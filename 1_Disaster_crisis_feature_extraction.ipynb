{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "646983b6"
      },
      "source": [
        "# Disaster crisis NLP Project (Nepal Earthquake dataset and Queensland_FLD datasets)"
      ],
      "id": "646983b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cc57ba7"
      },
      "source": [
        "## Import packages "
      ],
      "id": "8cc57ba7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9b752ec",
        "outputId": "d3b4f7ce-996d-48cd-87d5-5a48439bc2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.options.mode.chained_assignment = None  # default='warn' surpress chain assignment warning\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import nltk\n",
        "nltk.download('all') \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import re                                  \n",
        "import string\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from textblob import Word\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import gensim\n",
        "\n",
        "from numpy import savetxt\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# sklearn \n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "\n",
        "# matplotlib and seaborn for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "\n",
        "# turn off userwarnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#pip install tokenization"
      ],
      "id": "c9b752ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e351d79"
      },
      "source": [
        "## Data collection"
      ],
      "id": "9e351d79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvB53GsTiK-q"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded_Nepal_EQ = files.upload()\n",
        "# uploaded_Queensland_FLD = files.upload()"
      ],
      "id": "xvB53GsTiK-q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-D6sRrf7rLM"
      },
      "outputs": [],
      "source": [
        "# import io\n",
        "# Nepal_EQ = pd.read_csv(io.BytesIO(uploaded_Nepal_EQ['2015_Nepal_Earthquake_train.tsv']), delimiter='\\t',  encoding='iso-8859-1')\n",
        "# Queensland_FLD = pd.read_csv(io.BytesIO(uploaded_Queensland_FLD['train.csv']))\n",
        "# # Dataset is now stored in a Pandas Dataframe"
      ],
      "id": "i-D6sRrf7rLM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg5g5Txe6y51"
      },
      "outputs": [],
      "source": [
        "Nepal_EQ_path = '/content/drive/MyDrive/ACL_ICWSM_2018_datasets/nepal/2015_Nepal_Earthquake_train.tsv'\n",
        "Queensland_FLD_path = '/content/drive/MyDrive/ACL_ICWSM_2018_datasets/queensland/2013_Queensland_Floods_train.tsv'\n",
        "\n",
        "# Load TSV file into a Pandas DataFrame\n",
        "Nepal_EQ = pd.read_csv(Nepal_EQ_path, delimiter='\\t',  encoding='iso-8859-1')\n",
        "\n",
        "Queensland_FLD = pd.read_csv(Queensland_FLD_path, delimiter='\\t',  encoding='iso-8859-1')"
      ],
      "id": "Hg5g5Txe6y51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd62b4c5"
      },
      "outputs": [],
      "source": [
        "# # Load TSV file into a Pandas DataFrame\n",
        "# Nepal_EQ = pd.read_csv('/Users/musaphiri/Downloads/Disaster Crisis Dataset/ACL_ICWSM_2018_datasets/nepal/2015_Nepal_Earthquake_train.tsv', \n",
        "#                  delimiter='\\t',  encoding='iso-8859-1')\n",
        "\n",
        "# Queensland_FLD = pd.read_csv('/Users/musaphiri/Downloads/Disaster Crisis Dataset/nlp-getting-started/train.csv') "
      ],
      "id": "bd62b4c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "cac2cf10",
        "outputId": "07020d6d-7e2a-433f-8f5c-3ee8c95ec312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id  \\\n",
              "0  591902739002560512   \n",
              "1  592939706788216832   \n",
              "2  592591542168252416   \n",
              "3  591903009279385600   \n",
              "4  592099765271199744   \n",
              "\n",
              "                                                                                                                                                text  \\\n",
              "0  RT @AnupKaphle: #Nepal's prime minister addressed the country for 1st time since earthquake on Saturday. No concrete plans, lots of referenâ°Ã_   \n",
              "1                                            @jonsnowC4 So have we; read our friends blog from Lamjung where they are working http://t.co/jGpSacUQpe   \n",
              "2                                                                                      Lend a helping hand if you can #Nepal https://t.co/FdRrvC84EA   \n",
              "3                  @shilpaanand they've managed to reach Kathmandu but with the help of their guide - not through the official evacuation I believe.   \n",
              "4           Israel Sending Aid Teams to Nepal After Quake: Israel was sending a delegation to Nepal Saturday to determine ... http://t.co/fjRuwl9vZI   \n",
              "\n",
              "      label  \n",
              "0  relevant  \n",
              "1  relevant  \n",
              "2  relevant  \n",
              "3  relevant  \n",
              "4  relevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-359bb159-4276-4b74-8d80-e9fe9d86876a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>591902739002560512</td>\n",
              "      <td>RT @AnupKaphle: #Nepal's prime minister addressed the country for 1st time since earthquake on Saturday. No concrete plans, lots of referenâ°Ã_</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>592939706788216832</td>\n",
              "      <td>@jonsnowC4 So have we; read our friends blog from Lamjung where they are working http://t.co/jGpSacUQpe</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>592591542168252416</td>\n",
              "      <td>Lend a helping hand if you can #Nepal https://t.co/FdRrvC84EA</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>591903009279385600</td>\n",
              "      <td>@shilpaanand they've managed to reach Kathmandu but with the help of their guide - not through the official evacuation I believe.</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>592099765271199744</td>\n",
              "      <td>Israel Sending Aid Teams to Nepal After Quake: Israel was sending a delegation to Nepal Saturday to determine ... http://t.co/fjRuwl9vZI</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-359bb159-4276-4b74-8d80-e9fe9d86876a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-359bb159-4276-4b74-8d80-e9fe9d86876a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-359bb159-4276-4b74-8d80-e9fe9d86876a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Print the first five rows of the Nepal Earthquake DataFrame\n",
        "Nepal_EQ.head()"
      ],
      "id": "cac2cf10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "08b4ad01",
        "outputId": "7f5e0c0d-5b30-4cc9-c160-3a9ecb64b245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id  \\\n",
              "0  295541465013182465   \n",
              "1  295485717465935873   \n",
              "2  297292225811972097   \n",
              "3  297199686392094720   \n",
              "4  295527618449666049   \n",
              "\n",
              "                                                                                                                                   text  \\\n",
              "0                                                             I just though about the night I went clubbing with @mikal1988 and I cried   \n",
              "1                                             Looks like its going to be another long night courtesy #djoko and #murray #AustralianOpen   \n",
              "2  @LaniiBanani hahahaha I just told him id have to think about it :p he was like what I would do to u if u were in my arms + more haha   \n",
              "3                                                                    Off to meeting.... with so called... Baaps of mineral processing!!   \n",
              "4                                                                                              Doubt I'll be getting much sleep tonight   \n",
              "\n",
              "          label  \n",
              "0  not_relevant  \n",
              "1  not_relevant  \n",
              "2  not_relevant  \n",
              "3  not_relevant  \n",
              "4  not_relevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b90b931-7a6b-43d1-826e-b774ce907d3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>295541465013182465</td>\n",
              "      <td>I just though about the night I went clubbing with @mikal1988 and I cried</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>295485717465935873</td>\n",
              "      <td>Looks like its going to be another long night courtesy #djoko and #murray #AustralianOpen</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>297292225811972097</td>\n",
              "      <td>@LaniiBanani hahahaha I just told him id have to think about it :p he was like what I would do to u if u were in my arms + more haha</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>297199686392094720</td>\n",
              "      <td>Off to meeting.... with so called... Baaps of mineral processing!!</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>295527618449666049</td>\n",
              "      <td>Doubt I'll be getting much sleep tonight</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b90b931-7a6b-43d1-826e-b774ce907d3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b90b931-7a6b-43d1-826e-b774ce907d3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b90b931-7a6b-43d1-826e-b774ce907d3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Print the first five rows of the Queensland floods DataFrame\n",
        "Queensland_FLD.head()"
      ],
      "id": "08b4ad01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f17b2d93",
        "outputId": "35cf44d3-f52d-4a20-a389-1f9a3e4b3e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6899 entries, 0 to 6898\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   tweet_id  6899 non-null   int64 \n",
            " 1   text      6899 non-null   object\n",
            " 2   label     6899 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 161.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Print Nepal_EQ dataset information \n",
        "Nepal_EQ.info()"
      ],
      "id": "f17b2d93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f3b314",
        "outputId": "34ee3345-e76c-4b20-b252-664b80f8338c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6019 entries, 0 to 6018\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   tweet_id  6019 non-null   int64 \n",
            " 1   text      6019 non-null   object\n",
            " 2   label     6019 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 141.2+ KB\n"
          ]
        }
      ],
      "source": [
        "# Print Queensland_FLD dataset information \n",
        "Queensland_FLD.info()"
      ],
      "id": "a7f3b314"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec5f772c"
      },
      "source": [
        "## Data Preprocessing "
      ],
      "id": "ec5f772c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "30ce4c8c",
        "outputId": "5659462b-2d2a-40ca-f41e-c0bf025082f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                text  \\\n",
              "0  RT @AnupKaphle: #Nepal's prime minister addressed the country for 1st time since earthquake on Saturday. No concrete plans, lots of referenâ°Ã_   \n",
              "1                                            @jonsnowC4 So have we; read our friends blog from Lamjung where they are working http://t.co/jGpSacUQpe   \n",
              "2                                                                                      Lend a helping hand if you can #Nepal https://t.co/FdRrvC84EA   \n",
              "\n",
              "      label  \n",
              "0  relevant  \n",
              "1  relevant  \n",
              "2  relevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6a5433a-0c67-47ea-a1c0-1cf8f524b928\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @AnupKaphle: #Nepal's prime minister addressed the country for 1st time since earthquake on Saturday. No concrete plans, lots of referenâ°Ã_</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jonsnowC4 So have we; read our friends blog from Lamjung where they are working http://t.co/jGpSacUQpe</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lend a helping hand if you can #Nepal https://t.co/FdRrvC84EA</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6a5433a-0c67-47ea-a1c0-1cf8f524b928')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6a5433a-0c67-47ea-a1c0-1cf8f524b928 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6a5433a-0c67-47ea-a1c0-1cf8f524b928');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Create new Nepal_EQ dataset with only 2 features (text & label) \n",
        "NepalEQ_df = Nepal_EQ[['text', 'label']]\n",
        "NepalEQ_df.head(3)"
      ],
      "id": "30ce4c8c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b111299"
      },
      "source": [
        "# Create new Queensland_FLD dataset with only 2 features (text & label) \n"
      ],
      "id": "3b111299"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "xh71lZ11vm01",
        "outputId": "62eba9fc-7bfa-4eb7-9193-becbcc826492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                   text  \\\n",
              "0                                                             I just though about the night I went clubbing with @mikal1988 and I cried   \n",
              "1                                             Looks like its going to be another long night courtesy #djoko and #murray #AustralianOpen   \n",
              "2  @LaniiBanani hahahaha I just told him id have to think about it :p he was like what I would do to u if u were in my arms + more haha   \n",
              "\n",
              "          label  \n",
              "0  not_relevant  \n",
              "1  not_relevant  \n",
              "2  not_relevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6affdf8-5629-4611-af3b-8ad2354d1036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I just though about the night I went clubbing with @mikal1988 and I cried</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Looks like its going to be another long night courtesy #djoko and #murray #AustralianOpen</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@LaniiBanani hahahaha I just told him id have to think about it :p he was like what I would do to u if u were in my arms + more haha</td>\n",
              "      <td>not_relevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6affdf8-5629-4611-af3b-8ad2354d1036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6affdf8-5629-4611-af3b-8ad2354d1036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6affdf8-5629-4611-af3b-8ad2354d1036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "QueenslandFLD_df = Queensland_FLD[['text', 'label']]\n",
        "QueenslandFLD_df.head(3)"
      ],
      "id": "xh71lZ11vm01"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktiWA62QIu3N"
      },
      "source": [
        "### Number of hashtag characters"
      ],
      "id": "ktiWA62QIu3N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaimf8X_Is8y"
      },
      "outputs": [],
      "source": [
        "# # calculating hashtags from NepalEQ_df Text Data\n",
        "# NepalEQ_df['hashtags'] = NepalEQ_df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
        "# NepalEQ_df.head()"
      ],
      "id": "zaimf8X_Is8y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAkvZ6ysI0RR"
      },
      "outputs": [],
      "source": [
        "# # calculating hashtags from QueenslandFLD_df Text Data\n",
        "# QueenslandFLD_df['hashtags'] = QueenslandFLD_df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
        "# QueenslandFLD_df.head()"
      ],
      "id": "nAkvZ6ysI0RR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il4PVw4cI2pY"
      },
      "source": [
        "### Number of retweets"
      ],
      "id": "il4PVw4cI2pY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmO4HTptI5jC"
      },
      "outputs": [],
      "source": [
        "# # calculating hashtags from NepalEQ_df Text Data\n",
        "# NepalEQ_df['retweets'] = NepalEQ_df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('RT')]))\n",
        "# NepalEQ_df.head()"
      ],
      "id": "LmO4HTptI5jC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XvlyEIGI6Qn"
      },
      "outputs": [],
      "source": [
        "# # calculating retweets from QueenslandFLD_df Text Data\n",
        "# QueenslandFLD_df['retweets'] = QueenslandFLD_df['text'].apply(lambda x: len([x for x in x.split() if x.startswith('RT')]))\n",
        "# QueenslandFLD_df.head()"
      ],
      "id": "1XvlyEIGI6Qn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eca33b1c"
      },
      "source": [
        "### Converting to lower case"
      ],
      "id": "eca33b1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972c4ba0",
        "outputId": "d234b894-f553-4007-c853-69a393f863eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    rt @anupkaphle: #nepal's prime minister addressed the country for 1st time since earthquake on saturday. no concrete plans, lots of referenâ°ã_\n",
              "1                                              @jonsnowc4 so have we; read our friends blog from lamjung where they are working http://t.co/jgpsacuqpe\n",
              "2                                                                                        lend a helping hand if you can #nepal https://t.co/fdrrvc84ea\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Converting NepalEQ_df Text Data to Lowercase\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: \" \".join(x.lower()\n",
        "for x in x.split()))\n",
        "NepalEQ_df['text'].head(3)"
      ],
      "id": "972c4ba0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c57f274",
        "outputId": "0142c819-8dcb-4eee-9c0f-f32a763544ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                               i just though about the night i went clubbing with @mikal1988 and i cried\n",
              "1                                               looks like its going to be another long night courtesy #djoko and #murray #australianopen\n",
              "2    @laniibanani hahahaha i just told him id have to think about it :p he was like what i would do to u if u were in my arms + more haha\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Converting NepalEQ_df Text Data to Lowercase\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: \" \".join(x.lower()\n",
        "for x in x.split()))\n",
        "QueenslandFLD_df['text'].head(3)"
      ],
      "id": "2c57f274"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e499d91"
      },
      "source": [
        "### Removing URL links"
      ],
      "id": "4e499d91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a4ce75e"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Three expressions are used to remove URL links, one for URLs with https, the second for URLs with http, \n",
        "and the third for URLs without them, but with or without www.\n",
        "\"\"\"\n",
        "\n",
        "# Handling URL links for NepalEQ_df Text Data \n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r'http?:\\/\\/\\S+', '', x))\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
        "# Handling URL links for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r'http?:\\/\\/\\S+', '', x))\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))"
      ],
      "id": "2a4ce75e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96add960"
      },
      "source": [
        "### Removing place holders "
      ],
      "id": "96add960"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1d4cb36"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Some text cleaning may have already been done on the dataset which replaced some \n",
        "links with {link} and all the videos with [video]. So, the code below is used to remove the {link} and [video] \n",
        "text in the tweets_text.\n",
        "\"\"\"\n",
        "\n",
        "# Handling place holders for QueenslandFLD_df Text Data\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r'{link}', '', x))\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r\"\\[video\\]\", '', x))\n",
        "# Handling place holders for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r'{link}', '', x))\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r\"\\[video\\]\", '', x))"
      ],
      "id": "c1d4cb36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fff540"
      },
      "source": [
        "### Removing HTML reference characters"
      ],
      "id": "11fff540"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76d39fcb"
      },
      "outputs": [],
      "source": [
        "# Handling HTML reference characters for NepalEQ_df Text Data\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
        "# Handling HTML reference characters for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r'&[a-z]+;', '', x))"
      ],
      "id": "76d39fcb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41b0cc89"
      },
      "source": [
        "### Removing Non-Letter characters"
      ],
      "id": "41b0cc89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8c792ea"
      },
      "outputs": [],
      "source": [
        "# Handling Non-Letter characters for NepalEQ_df Text Data\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))\n",
        "# Handling Non-Letter characters for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))"
      ],
      "id": "a8c792ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dd47587"
      },
      "source": [
        "### Removing Twitter handles "
      ],
      "id": "5dd47587"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06c7b027"
      },
      "outputs": [],
      "source": [
        "# Handling Twitter handles for NepalEQ_df Text Data\n",
        "NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: re.sub(r'@mention', '', x))\n",
        "# Handling Twitter handles for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: re.sub(r'@mention', '', x))"
      ],
      "id": "06c7b027"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66c7c3e9"
      },
      "source": [
        "### Stemming"
      ],
      "id": "66c7c3e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "084e0382"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# This is used to find the root of a word. For example, “fish,” “fishes,” and “fishing” are stemmed into fish.\n",
        "# \"\"\"\n",
        "# # Initialize stem object\n",
        "# st = PorterStemmer()\n",
        "\n",
        "# # Stemming text for NepalEQ_df Text Data\n",
        "# NepalEQ_df['text'] = NepalEQ_df['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "# # Stemming text for QueenslandFLD_df Text Data\n",
        "# QueenslandFLD_df['text'] = QueenslandFLD_df['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
      ],
      "id": "084e0382"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af5c6b1d"
      },
      "source": [
        "### Lemmatizing"
      ],
      "id": "af5c6b1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d52aab39"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# Lemmatization is a process of\n",
        "# extracting a root word by considering the vocabulary. For example, “good”, “better”, or “best” is lemmatized into good.\n",
        "# \"\"\"\n",
        "\n",
        "# # Lemmatizing text for NepalEQ_df Text Data\n",
        "# NepalEQ_df['tokens'] = NepalEQ_df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "# # Lemmatizing for QueenslandFLD_df Text Data\n",
        "# QueenslandFLD_df['tokens'] = QueenslandFLD_df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
      ],
      "id": "d52aab39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd3ceda8"
      },
      "source": [
        "### Tokenize the text"
      ],
      "id": "cd3ceda8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a2f3452"
      },
      "outputs": [],
      "source": [
        "# Initialize token object\n",
        "tknzr = TweetTokenizer()\n",
        "\n",
        "# Tokenize NepalEQ_df Text Data\n",
        "NepalEQ_df['tokens'] = NepalEQ_df['text'].apply(tknzr.tokenize)\n",
        "# Tokenize QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['tokens'] = QueenslandFLD_df['text'].apply(tknzr.tokenize)"
      ],
      "id": "9a2f3452"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2a52861"
      },
      "source": [
        "### Removing Punctuation"
      ],
      "id": "d2a52861"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc365e66"
      },
      "outputs": [],
      "source": [
        "# define punctuation list\n",
        "PUNCUATION_LIST = list(string.punctuation)\n",
        "\n",
        "# define punction function\n",
        "def remove_punctuation(word_list):\n",
        "    \"\"\"Remove punctuation tokens from a list of tokens\"\"\"\n",
        "    return [w for w in word_list if w not in PUNCUATION_LIST]\n",
        "\n",
        "# Removing Punctuation for NepalEQ_df Token Data\n",
        "NepalEQ_df['tokens'] = NepalEQ_df['tokens'].apply(remove_punctuation)\n",
        "# Removing Punctuation for QueenslandFLD_df Token Data\n",
        "QueenslandFLD_df['tokens'] = QueenslandFLD_df['tokens'].apply(remove_punctuation)"
      ],
      "id": "dc365e66"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "128dd7ef"
      },
      "source": [
        "### Lemmatizing"
      ],
      "id": "128dd7ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8cae7f"
      },
      "outputs": [],
      "source": [
        "def lemmatize_word(text):\n",
        "    \"\"\"\n",
        "        Lemmatize the tokenized words\n",
        "    \"\"\"\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
        "    return lemma\n",
        "\n",
        "# Test without POS Tagging\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Lemmatizing text for NepalEQ_df Text Data\n",
        "NepalEQ_df['lemmatize_word'] = NepalEQ_df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Lemmatizing for QueenslandFLD_df Text Data\n",
        "QueenslandFLD_df['lemmatize_word'] = QueenslandFLD_df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
      ],
      "id": "6a8cae7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "2d642b95",
        "outputId": "5bb855cf-dbfd-4502-c848-92be494cb9ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                 text  \\\n",
              "0                                                                i just though about the night i went clubbing with mikal and i cried   \n",
              "1                                           looks like its going to be another long night courtesy #djoko and #murray #australianopen   \n",
              "2  laniibanani hahahaha i just told him id have to think about it :p he was like what i would do to u if u were in my arms  more haha   \n",
              "3                                                                           off to meeting with so called baaps of mineral processing   \n",
              "4                                                                                            doubt i'll be getting much sleep tonight   \n",
              "\n",
              "          label  \\\n",
              "0  not_relevant   \n",
              "1  not_relevant   \n",
              "2  not_relevant   \n",
              "3  not_relevant   \n",
              "4  not_relevant   \n",
              "\n",
              "                                                                                                                                                             tokens  \\\n",
              "0                                                                               [i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]   \n",
              "1                                                          [looks, like, its, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]   \n",
              "2  [laniibanani, hahahaha, i, just, told, him, id, have, to, think, about, it, :p, he, was, like, what, i, would, do, to, u, if, u, were, in, my, arms, more, haha]   \n",
              "3                                                                                              [off, to, meeting, with, so, called, baaps, of, mineral, processing]   \n",
              "4                                                                                                                  [doubt, i'll, be, getting, much, sleep, tonight]   \n",
              "\n",
              "                                                                                                                                                   lemmatize_word  \n",
              "0                                                                             [i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]  \n",
              "1                                                          [look, like, it, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]  \n",
              "2  [laniibanani, hahahaha, i, just, told, him, id, have, to, think, about, it, :p, he, wa, like, what, i, would, do, to, u, if, u, were, in, my, arm, more, haha]  \n",
              "3                                                                                            [off, to, meeting, with, so, called, baaps, of, mineral, processing]  \n",
              "4                                                                                                                [doubt, i'll, be, getting, much, sleep, tonight]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-584dc2d2-8f73-4068-9e93-5993ad83ff2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>lemmatize_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i just though about the night i went clubbing with mikal and i cried</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]</td>\n",
              "      <td>[i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>looks like its going to be another long night courtesy #djoko and #murray #australianopen</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[looks, like, its, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]</td>\n",
              "      <td>[look, like, it, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>laniibanani hahahaha i just told him id have to think about it :p he was like what i would do to u if u were in my arms  more haha</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[laniibanani, hahahaha, i, just, told, him, id, have, to, think, about, it, :p, he, was, like, what, i, would, do, to, u, if, u, were, in, my, arms, more, haha]</td>\n",
              "      <td>[laniibanani, hahahaha, i, just, told, him, id, have, to, think, about, it, :p, he, wa, like, what, i, would, do, to, u, if, u, were, in, my, arm, more, haha]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>off to meeting with so called baaps of mineral processing</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[off, to, meeting, with, so, called, baaps, of, mineral, processing]</td>\n",
              "      <td>[off, to, meeting, with, so, called, baaps, of, mineral, processing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doubt i'll be getting much sleep tonight</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[doubt, i'll, be, getting, much, sleep, tonight]</td>\n",
              "      <td>[doubt, i'll, be, getting, much, sleep, tonight]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-584dc2d2-8f73-4068-9e93-5993ad83ff2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-584dc2d2-8f73-4068-9e93-5993ad83ff2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-584dc2d2-8f73-4068-9e93-5993ad83ff2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "QueenslandFLD_df.head()"
      ],
      "id": "2d642b95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c0725e3"
      },
      "source": [
        "## Feature engineering  "
      ],
      "id": "7c0725e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9656cf0f"
      },
      "source": [
        "### Part of Speech Tagging (POS Tagging)"
      ],
      "id": "9656cf0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "264b1101"
      },
      "outputs": [],
      "source": [
        "wordnet_map = {\"N\":wordnet.NOUN, \n",
        "               \"V\":wordnet.VERB, \n",
        "               \"J\":wordnet.ADJ, \n",
        "               \"R\":wordnet.ADV\n",
        "              }\n",
        "    \n",
        "train_sents = brown.tagged_sents(categories='news')\n",
        "t0 = nltk.DefaultTagger('NN')\n",
        "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
        "\n",
        "def pos_tag_wordnet(text, pos_tag_type=\"pos_tag\"):\n",
        "    \"\"\"\n",
        "        Create pos_tag with wordnet format\n",
        "    \"\"\"\n",
        "    pos_tagged_text = t2.tag(text)\n",
        "    \n",
        "    # map the pos tagging output with wordnet output \n",
        "    pos_tagged_text = [(word, wordnet_map.get(pos_tag[0])) if pos_tag[0] in wordnet_map.keys() else (word, wordnet.NOUN) for (word, pos_tag) in pos_tagged_text ]\n",
        "    return pos_tagged_text\n",
        "\n",
        "NepalEQ_df['combined_postag_wnet'] = NepalEQ_df['lemmatize_word'].apply(lambda x: pos_tag_wordnet(x))\n",
        "NepalEQ_df['joined_words'] = [' '.join(map(str, l)) for l in NepalEQ_df['lemmatize_word']] # join back to text\n",
        "QueenslandFLD_df['combined_postag_wnet'] = QueenslandFLD_df['lemmatize_word'].apply(lambda x: pos_tag_wordnet(x))\n",
        "QueenslandFLD_df['joined_words'] = [' '.join(map(str, l)) for l in QueenslandFLD_df['lemmatize_word']] # join back to text"
      ],
      "id": "264b1101"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zyyIkgZ1RuA"
      },
      "outputs": [],
      "source": [
        "# Extract features based on the frequency of certain POS tags for NepalEQ_df\n",
        "NepalEQ_df['Noun_Count'] = NepalEQ_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['n'])\n",
        "NepalEQ_df['Verb_Count'] = NepalEQ_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['v'])\n",
        "NepalEQ_df['Adjective_Count'] = NepalEQ_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['j'])\n",
        "NepalEQ_df['Adverb_Count'] = NepalEQ_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['r'])\n",
        "\n",
        "# Normalize the column\n",
        "# norm1 = np.linalg.norm(NepalEQ_df['hashtags'])\n",
        "# NepalEQ_df['hashtags_normalized'] = NepalEQ_df['hashtags'] / norm1\n",
        "# norm2 = np.linalg.norm(NepalEQ_df['hashtags'])\n",
        "# NepalEQ_df['retweets_normalized'] = NepalEQ_df['retweets'] / norm2\n",
        "\n",
        "# norm3 = np.linalg.norm(NepalEQ_df['Noun_Count'])\n",
        "# NepalEQ_df['Noun_Count_normalized'] = NepalEQ_df['Noun_Count'] / norm3\n",
        "# norm4 = np.linalg.norm(NepalEQ_df['Verb_Count'])\n",
        "# NepalEQ_df['Verb_Count_normalized'] = NepalEQ_df['Verb_Count'] / norm4\n",
        "# norm5 = np.linalg.norm(NepalEQ_df['Adjective_Count'])\n",
        "# NepalEQ_df['Adjective_Count_normalized'] = NepalEQ_df['Adjective_Count'] / norm5\n",
        "# norm6 = np.linalg.norm(NepalEQ_df['Adverb_Count'])\n",
        "# NepalEQ_df['Adverb_Count_normalized'] = NepalEQ_df['Adverb_Count'] / norm6\n",
        "\n",
        "# NepalEQ_df['hashtags_normalized'] = NepalEQ_df['hashtags'].apply(lambda x: (x - NepalEQ_df['hashtags'].min()) / (NepalEQ_df['hashtags'].max() - NepalEQ_df['hashtags'].min()) * 2 - 1)\n",
        "# NepalEQ_df['retweets_normalized'] = NepalEQ_df['retweets'].apply(lambda x: (x - NepalEQ_df['retweets'].min()) / (NepalEQ_df['retweets'].max() - NepalEQ_df['retweets'].min()) * 2 - 1)\n",
        "# NepalEQ_df['Noun_Count_normalized'] = NepalEQ_df['Noun_Count'].apply(lambda x: (x - NepalEQ_df['Noun_Count'].min()) / (NepalEQ_df['Noun_Count'].max() - NepalEQ_df['Noun_Count'].min()) * 2 - 1)\n",
        "# NepalEQ_df['Verb_Count_normalized'] = NepalEQ_df['Verb_Count'].apply(lambda x: (x - NepalEQ_df['Verb_Count'].min()) / (NepalEQ_df['Verb_Count'].max() - NepalEQ_df['Verb_Count'].min()) * 2 - 1)\n",
        "# NepalEQ_df['Adjective_Count_normalized'] = NepalEQ_df['Adjective_Count'].apply(lambda x: (x - NepalEQ_df['Adjective_Count'].min()) / (NepalEQ_df['Adjective_Count'].max() - NepalEQ_df['Adjective_Count'].min()) * 2 - 1)\n",
        "# NepalEQ_df['Adverb_Count_normalized'] = NepalEQ_df['Adverb_Count'].apply(lambda x: (x - NepalEQ_df['Adverb_Count'].min()) / (NepalEQ_df['Adverb_Count'].max() - NepalEQ_df['Adverb_Count'].min()) * 2 - 1)\n",
        "\n",
        "# Extract features based on the frequency of certain POS tags for NepalEQ_df\n",
        "QueenslandFLD_df['Noun_Count'] = QueenslandFLD_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['n'])\n",
        "QueenslandFLD_df['Verb_Count'] = QueenslandFLD_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['v'])\n",
        "QueenslandFLD_df['Adjective_Count'] = QueenslandFLD_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['j'])\n",
        "QueenslandFLD_df['Adverb_Count'] = QueenslandFLD_df['combined_postag_wnet'].apply(lambda x: Counter(tag for word, tag in x)['r'])\n",
        "\n",
        "# Normalize columns \n",
        "# norm7 = np.linalg.norm(QueenslandFLD_df['hashtags'])\n",
        "# QueenslandFLD_df['hashtags_normalized'] = QueenslandFLD_df['hashtags'] / norm7\n",
        "# norm8 = np.linalg.norm(QueenslandFLD_df['hashtags'])\n",
        "# QueenslandFLD_df['retweets_normalized'] = QueenslandFLD_df['retweets'] / norm8\n",
        "\n",
        "# norm9 = np.linalg.norm(QueenslandFLD_df['Noun_Count'])\n",
        "# QueenslandFLD_df['Noun_Count_normalized'] = QueenslandFLD_df['Noun_Count'] / norm9\n",
        "# norm10 = np.linalg.norm(QueenslandFLD_df['Verb_Count'])\n",
        "# QueenslandFLD_df['Verb_Count_normalized'] = QueenslandFLD_df['Verb_Count'] / norm10\n",
        "# norm11 = np.linalg.norm(QueenslandFLD_df['Adjective_Count'])\n",
        "# QueenslandFLD_df['Adjective_Count_normalized'] = QueenslandFLD_df['Adjective_Count'] / norm11\n",
        "# norm12 = np.linalg.norm(QueenslandFLD_df['Adverb_Count'])\n",
        "# QueenslandFLD_df['Adverb_Count_normalized'] = QueenslandFLD_df['Adverb_Count'] / norm12\n",
        "\n",
        "# # Normalize columns \n",
        "# QueenslandFLD_df['hashtags_normalized'] = QueenslandFLD_df['hashtags'].apply(lambda x: (x - QueenslandFLD_df['hashtags'].min()) / (QueenslandFLD_df['hashtags'].max() - QueenslandFLD_df['hashtags'].min()) * 2 - 1)\n",
        "# QueenslandFLD_df['retweets_normalized'] = QueenslandFLD_df['retweets'].apply(lambda x: (x - QueenslandFLD_df['retweets'].min()) / (QueenslandFLD_df['retweets'].max() - QueenslandFLD_df['retweets'].min()) * 2 - 1)\n",
        "# QueenslandFLD_df['Noun_Count_normalized'] = QueenslandFLD_df['Noun_Count'].apply(lambda x: (x - QueenslandFLD_df['Noun_Count'].min()) / (QueenslandFLD_df['Noun_Count'].max() - QueenslandFLD_df['Noun_Count'].min()) * 2 - 1)\n",
        "# QueenslandFLD_df['Verb_Count_normalized'] = QueenslandFLD_df['Verb_Count'].apply(lambda x: (x - QueenslandFLD_df['Verb_Count'].min()) / (QueenslandFLD_df['Verb_Count'].max() - QueenslandFLD_df['Verb_Count'].min()) * 2 - 1)\n",
        "# QueenslandFLD_df['Adjective_Count_normalized'] = QueenslandFLD_df['Adjective_Count'].apply(lambda x: (x - QueenslandFLD_df['Adjective_Count'].min()) / (QueenslandFLD_df['Adjective_Count'].max() - QueenslandFLD_df['Adjective_Count'].min()) * 2 - 1)\n",
        "# QueenslandFLD_df['Adverb_Count_normalized'] = QueenslandFLD_df['Adverb_Count'].apply(lambda x: (x - QueenslandFLD_df['Adverb_Count'].min()) / (QueenslandFLD_df['Adverb_Count'].max() - QueenslandFLD_df['Adverb_Count'].min()) * 2 - 1)\n",
        "\n"
      ],
      "id": "9zyyIkgZ1RuA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "Y64YGkCb6CYz",
        "outputId": "1b0ab162-c445-4f9d-b5f3-cfe93254c464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                      text  \\\n",
              "0  rt anupkaphle: #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plans lots of referen   \n",
              "1                                                          jonsnowc so have we; read our friends blog from lamjung where they are working    \n",
              "\n",
              "      label  \\\n",
              "0  relevant   \n",
              "1  relevant   \n",
              "\n",
              "                                                                                                                                                         tokens  \\\n",
              "0  [rt, anupkaphle, #nepal's, prime, minister, addressed, the, country, for, st, time, since, earthquake, on, saturday, no, concrete, plans, lots, of, referen]   \n",
              "1                                                                  [jonsnowc, so, have, we, read, our, friends, blog, from, lamjung, where, they, are, working]   \n",
              "\n",
              "                                                                                                                                               lemmatize_word  \\\n",
              "0  [rt, anupkaphle, #nepal's, prime, minister, addressed, the, country, for, st, time, since, earthquake, on, saturday, no, concrete, plan, lot, of, referen]   \n",
              "1                                                                 [jonsnowc, so, have, we, read, our, friend, blog, from, lamjung, where, they, are, working]   \n",
              "\n",
              "                                                                                                                                                                                                                                                  combined_postag_wnet  \\\n",
              "0  [(rt, n), (anupkaphle, n), (#nepal's, n), (prime, a), (minister, n), (addressed, v), (the, n), (country, n), (for, n), (st, n), (time, n), (since, n), (earthquake, n), (on, n), (saturday, n), (no, n), (concrete, a), (plan, n), (lot, n), (of, n), (referen, n)]   \n",
              "1                                                                                                    [(jonsnowc, n), (so, n), (have, n), (we, n), (read, v), (our, n), (friend, n), (blog, n), (from, n), (lamjung, n), (where, n), (they, n), (are, n), (working, v)]   \n",
              "\n",
              "                                                                                                                           joined_words  \\\n",
              "0  rt anupkaphle #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plan lot of referen   \n",
              "1                                                          jonsnowc so have we read our friend blog from lamjung where they are working   \n",
              "\n",
              "   Noun_Count  Verb_Count  Adjective_Count  Adverb_Count  \n",
              "0          18           1                0             0  \n",
              "1          12           2                0             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82435d4e-1535-41e0-b405-abd6ef2c77ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>lemmatize_word</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>joined_words</th>\n",
              "      <th>Noun_Count</th>\n",
              "      <th>Verb_Count</th>\n",
              "      <th>Adjective_Count</th>\n",
              "      <th>Adverb_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt anupkaphle: #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plans lots of referen</td>\n",
              "      <td>relevant</td>\n",
              "      <td>[rt, anupkaphle, #nepal's, prime, minister, addressed, the, country, for, st, time, since, earthquake, on, saturday, no, concrete, plans, lots, of, referen]</td>\n",
              "      <td>[rt, anupkaphle, #nepal's, prime, minister, addressed, the, country, for, st, time, since, earthquake, on, saturday, no, concrete, plan, lot, of, referen]</td>\n",
              "      <td>[(rt, n), (anupkaphle, n), (#nepal's, n), (prime, a), (minister, n), (addressed, v), (the, n), (country, n), (for, n), (st, n), (time, n), (since, n), (earthquake, n), (on, n), (saturday, n), (no, n), (concrete, a), (plan, n), (lot, n), (of, n), (referen, n)]</td>\n",
              "      <td>rt anupkaphle #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plan lot of referen</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jonsnowc so have we; read our friends blog from lamjung where they are working</td>\n",
              "      <td>relevant</td>\n",
              "      <td>[jonsnowc, so, have, we, read, our, friends, blog, from, lamjung, where, they, are, working]</td>\n",
              "      <td>[jonsnowc, so, have, we, read, our, friend, blog, from, lamjung, where, they, are, working]</td>\n",
              "      <td>[(jonsnowc, n), (so, n), (have, n), (we, n), (read, v), (our, n), (friend, n), (blog, n), (from, n), (lamjung, n), (where, n), (they, n), (are, n), (working, v)]</td>\n",
              "      <td>jonsnowc so have we read our friend blog from lamjung where they are working</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82435d4e-1535-41e0-b405-abd6ef2c77ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82435d4e-1535-41e0-b405-abd6ef2c77ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82435d4e-1535-41e0-b405-abd6ef2c77ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "NepalEQ_df.head(2)"
      ],
      "id": "Y64YGkCb6CYz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "iGdxosAL6FWd",
        "outputId": "9e18e5ed-d8a5-4ef2-a685-668b8b9469a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                        text  \\\n",
              "0                       i just though about the night i went clubbing with mikal and i cried   \n",
              "1  looks like its going to be another long night courtesy #djoko and #murray #australianopen   \n",
              "\n",
              "          label  \\\n",
              "0  not_relevant   \n",
              "1  not_relevant   \n",
              "\n",
              "                                                                                                     tokens  \\\n",
              "0                       [i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]   \n",
              "1  [looks, like, its, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]   \n",
              "\n",
              "                                                                                           lemmatize_word  \\\n",
              "0                     [i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]   \n",
              "1  [look, like, it, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]   \n",
              "\n",
              "                                                                                                                                                           combined_postag_wnet  \\\n",
              "0                     [(i, n), (just, r), (though, n), (about, r), (the, n), (night, n), (i, n), (went, v), (clubbing, n), (with, n), (mikal, n), (and, n), (i, n), (cried, n)]   \n",
              "1  [(look, v), (like, n), (it, n), (going, v), (to, n), (be, n), (another, n), (long, a), (night, n), (courtesy, n), (#djoko, n), (and, n), (#murray, n), (#australianopen, n)]   \n",
              "\n",
              "                                                                              joined_words  \\\n",
              "0                     i just though about the night i went clubbing with mikal and i cried   \n",
              "1  look like it going to be another long night courtesy #djoko and #murray #australianopen   \n",
              "\n",
              "   Noun_Count  Verb_Count  Adjective_Count  Adverb_Count  \n",
              "0          11           1                0             2  \n",
              "1          11           2                0             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b79c9880-33a3-4986-9b37-2c81d35cb026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>lemmatize_word</th>\n",
              "      <th>combined_postag_wnet</th>\n",
              "      <th>joined_words</th>\n",
              "      <th>Noun_Count</th>\n",
              "      <th>Verb_Count</th>\n",
              "      <th>Adjective_Count</th>\n",
              "      <th>Adverb_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i just though about the night i went clubbing with mikal and i cried</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]</td>\n",
              "      <td>[i, just, though, about, the, night, i, went, clubbing, with, mikal, and, i, cried]</td>\n",
              "      <td>[(i, n), (just, r), (though, n), (about, r), (the, n), (night, n), (i, n), (went, v), (clubbing, n), (with, n), (mikal, n), (and, n), (i, n), (cried, n)]</td>\n",
              "      <td>i just though about the night i went clubbing with mikal and i cried</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>looks like its going to be another long night courtesy #djoko and #murray #australianopen</td>\n",
              "      <td>not_relevant</td>\n",
              "      <td>[looks, like, its, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]</td>\n",
              "      <td>[look, like, it, going, to, be, another, long, night, courtesy, #djoko, and, #murray, #australianopen]</td>\n",
              "      <td>[(look, v), (like, n), (it, n), (going, v), (to, n), (be, n), (another, n), (long, a), (night, n), (courtesy, n), (#djoko, n), (and, n), (#murray, n), (#australianopen, n)]</td>\n",
              "      <td>look like it going to be another long night courtesy #djoko and #murray #australianopen</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b79c9880-33a3-4986-9b37-2c81d35cb026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b79c9880-33a3-4986-9b37-2c81d35cb026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b79c9880-33a3-4986-9b37-2c81d35cb026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "QueenslandFLD_df.head(2)"
      ],
      "id": "iGdxosAL6FWd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bx06K4Xsdli"
      },
      "source": [
        "#### Hashtags"
      ],
      "id": "_Bx06K4Xsdli"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "F5q28znVsdli",
        "outputId": "e0bee115-570e-4ef2-d77c-020466979e91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   aa  aamaadmiparty  aap  aapkilledfarmer  aapnautanki  aaprallymurder  abc  \\\n",
              "0   0              0    0                0            0               0    0   \n",
              "1   0              0    0                0            0               0    0   \n",
              "2   0              0    0                0            0               0    0   \n",
              "3   0              0    0                0            0               0    0   \n",
              "4   0              0    0                0            0               0    0   \n",
              "\n",
              "   abdsc  abgurung  abitfurther  ...  yogi  youcannotpreventearthquakes  \\\n",
              "0      0         0            0  ...     0                            0   \n",
              "1      0         0            0  ...     0                            0   \n",
              "2      0         0            0  ...     0                            0   \n",
              "3      0         0            0  ...     0                            0   \n",
              "4      0         0            0  ...     0                            0   \n",
              "\n",
              "   youtube  ypg  ypj  yug  yunakim  yyc  zippednews  zuckerberg  \n",
              "0        0    0    0    0        0    0           0           0  \n",
              "1        0    0    0    0        0    0           0           0  \n",
              "2        0    0    0    0        0    0           0           0  \n",
              "3        0    0    0    0        0    0           0           0  \n",
              "4        0    0    0    0        0    0           0           0  \n",
              "\n",
              "[5 rows x 1674 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b4f64f8-3bbb-4cc6-974f-38d66f8f4733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aamaadmiparty</th>\n",
              "      <th>aap</th>\n",
              "      <th>aapkilledfarmer</th>\n",
              "      <th>aapnautanki</th>\n",
              "      <th>aaprallymurder</th>\n",
              "      <th>abc</th>\n",
              "      <th>abdsc</th>\n",
              "      <th>abgurung</th>\n",
              "      <th>abitfurther</th>\n",
              "      <th>...</th>\n",
              "      <th>yogi</th>\n",
              "      <th>youcannotpreventearthquakes</th>\n",
              "      <th>youtube</th>\n",
              "      <th>ypg</th>\n",
              "      <th>ypj</th>\n",
              "      <th>yug</th>\n",
              "      <th>yunakim</th>\n",
              "      <th>yyc</th>\n",
              "      <th>zippednews</th>\n",
              "      <th>zuckerberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1674 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b4f64f8-3bbb-4cc6-974f-38d66f8f4733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b4f64f8-3bbb-4cc6-974f-38d66f8f4733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b4f64f8-3bbb-4cc6-974f-38d66f8f4733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Extract hashtags from tweet text\n",
        "NepalEQ_hashtags = NepalEQ_df['joined_words'].str.findall(r'#(\\w+)')\n",
        "\n",
        "# Apply one-hot encoding to hashtags\n",
        "mlb = MultiLabelBinarizer()\n",
        "one_hot = mlb.fit_transform(NepalEQ_hashtags)\n",
        "\n",
        "# Create a new dataframe with one-hot encoded hashtag features\n",
        "NepalEQ_hashtag_df = pd.DataFrame(one_hot, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate the original tweet dataframe with the new hashtag features dataframe\n",
        "# NepalEQ_hashtag_df = pd.concat([tweets, hashtag_df], axis=1)\n",
        "\n",
        "# View the resulting dataframe\n",
        "NepalEQ_hashtag_df.head()"
      ],
      "id": "F5q28znVsdli"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "LysYhmLls43P",
        "outputId": "61929341-89fc-4e8d-e801-ddcd7c2bb207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   aacta  abba  abcmobile  abcnews  ace  acnc  addicted  adi  adityaramadana  \\\n",
              "0      0     0          0        0    0     0         0    0               0   \n",
              "1      0     0          0        0    0     0         0    0               0   \n",
              "2      0     0          0        0    0     0         0    0               0   \n",
              "3      0     0          0        0    0     0         0    0               0   \n",
              "4      0     0          0        0    0     0         0    0               0   \n",
              "\n",
              "   aftermath  ...  year  yeerboy  yeppoon  yoga  yolo  younghealers  \\\n",
              "0          0  ...     0        0        0     0     0             0   \n",
              "1          0  ...     0        0        0     0     0             0   \n",
              "2          0  ...     0        0        0     0     0             0   \n",
              "3          0  ...     0        0        0     0     0             0   \n",
              "4          0  ...     0        0        0     0     0             0   \n",
              "\n",
              "   youreonlyonce  yuck  yumyum  zerodarkthirty  \n",
              "0              0     0       0               0  \n",
              "1              0     0       0               0  \n",
              "2              0     0       0               0  \n",
              "3              0     0       0               0  \n",
              "4              0     0       0               0  \n",
              "\n",
              "[5 rows x 1009 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64337c33-b42d-4c19-b74e-6d7173386a5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aacta</th>\n",
              "      <th>abba</th>\n",
              "      <th>abcmobile</th>\n",
              "      <th>abcnews</th>\n",
              "      <th>ace</th>\n",
              "      <th>acnc</th>\n",
              "      <th>addicted</th>\n",
              "      <th>adi</th>\n",
              "      <th>adityaramadana</th>\n",
              "      <th>aftermath</th>\n",
              "      <th>...</th>\n",
              "      <th>year</th>\n",
              "      <th>yeerboy</th>\n",
              "      <th>yeppoon</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yolo</th>\n",
              "      <th>younghealers</th>\n",
              "      <th>youreonlyonce</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yumyum</th>\n",
              "      <th>zerodarkthirty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1009 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64337c33-b42d-4c19-b74e-6d7173386a5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64337c33-b42d-4c19-b74e-6d7173386a5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64337c33-b42d-4c19-b74e-6d7173386a5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Extract hashtags from tweet text\n",
        "QueenslandFLD_hashtags = QueenslandFLD_df['joined_words'].str.findall(r'#(\\w+)')\n",
        "\n",
        "# Apply one-hot encoding to hashtags\n",
        "mlb = MultiLabelBinarizer()\n",
        "one_hot = mlb.fit_transform(QueenslandFLD_hashtags)\n",
        "\n",
        "# Create a new dataframe with one-hot encoded hashtag features\n",
        "QueenslandFLD_hashtag_df = pd.DataFrame(one_hot, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate the original tweet dataframe with the new hashtag features dataframe\n",
        "# NepalEQ_hashtag_df = pd.concat([tweets, hashtag_df], axis=1)\n",
        "\n",
        "# View the resulting dataframe\n",
        "QueenslandFLD_hashtag_df.head()"
      ],
      "id": "LysYhmLls43P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpZaAXQbsdli"
      },
      "source": [
        "#### Retweet"
      ],
      "id": "GpZaAXQbsdli"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uSP9KIKR0Zi5",
        "outputId": "adbe6b20-d852-440a-def2-1f6d872255bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   is_retweet\n",
              "0         1.0\n",
              "1         1.0\n",
              "2         1.0\n",
              "3         1.0\n",
              "4         1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84a01012-7ff8-4a62-9858-d60e4329c37d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84a01012-7ff8-4a62-9858-d60e4329c37d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84a01012-7ff8-4a62-9858-d60e4329c37d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84a01012-7ff8-4a62-9858-d60e4329c37d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Example tweet dataframe\n",
        "#tweets = pd.DataFrame({'text': ['Just tweeted', 'RT @username: Some tweet', 'RT @otheruser: Another tweet']})\n",
        "\n",
        "# Create a boolean mask indicating which tweets are retweets\n",
        "NepalEQ_retweet = NepalEQ_df['joined_words'].str.startswith('RT')\n",
        "\n",
        "# Apply one-hot encoding to the boolean mask\n",
        "encoder = OneHotEncoder()\n",
        "NepalEQ_retweet_encoded = encoder.fit_transform(NepalEQ_retweet.values.reshape(-1, 1)).toarray()\n",
        "\n",
        "# Create a new dataframe with one-hot encoded retweet features\n",
        "NepalEQ_retweet_df = pd.DataFrame(NepalEQ_retweet_encoded, columns=['is_retweet'])\n",
        "\n",
        "# Concatenate the original tweet dataframe with the new retweet features dataframe\n",
        "#NepalEQ_new_tweets = pd.concat([tweets, retweet_df], axis=1)\n",
        "\n",
        "# View the resulting dataframe\n",
        "NepalEQ_retweet_df.head()"
      ],
      "id": "uSP9KIKR0Zi5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ef_5jjSc2lZY",
        "outputId": "c34e6dc3-9905-40f0-fc75-0d11a8750640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   is_retweet\n",
              "0         1.0\n",
              "1         1.0\n",
              "2         1.0\n",
              "3         1.0\n",
              "4         1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df828cba-c175-40b0-b669-902e87ddf5f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df828cba-c175-40b0-b669-902e87ddf5f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df828cba-c175-40b0-b669-902e87ddf5f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df828cba-c175-40b0-b669-902e87ddf5f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Example tweet dataframe\n",
        "#tweets = pd.DataFrame({'text': ['Just tweeted', 'RT @username: Some tweet', 'RT @otheruser: Another tweet']})\n",
        "\n",
        "# Create a boolean mask indicating which tweets are retweets\n",
        "QueenslandFLD_retweet = QueenslandFLD_df['joined_words'].str.startswith('RT')\n",
        "\n",
        "# Apply one-hot encoding to the boolean mask\n",
        "encoder = OneHotEncoder()\n",
        "QueenslandFLD_retweet_encoded = encoder.fit_transform(QueenslandFLD_retweet.values.reshape(-1, 1)).toarray()\n",
        "\n",
        "# Create a new dataframe with one-hot encoded retweet features\n",
        "QueenslandFLD_retweet_df = pd.DataFrame(QueenslandFLD_retweet_encoded, columns=['is_retweet'])\n",
        "\n",
        "# Concatenate the original tweet dataframe with the new retweet features dataframe\n",
        "#NepalEQ_new_tweets = pd.concat([tweets, retweet_df], axis=1)\n",
        "\n",
        "# View the resulting dataframe\n",
        "QueenslandFLD_retweet_df.head()"
      ],
      "id": "Ef_5jjSc2lZY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99893b62"
      },
      "source": [
        "### Bag of words"
      ],
      "id": "99893b62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bbd072b"
      },
      "outputs": [],
      "source": [
        "def cv(data, ngram = 1, MAX_NB_WORDS = 75000):\n",
        "    count_vectorizer = CountVectorizer(ngram_range = (ngram, ngram), max_features = MAX_NB_WORDS)\n",
        "    emb = count_vectorizer.fit_transform(data).toarray()\n",
        "    print(\"count vectorize with\", str(np.array(emb).shape[1]), \"features\")\n",
        "    return emb, count_vectorizer"
      ],
      "id": "7bbd072b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "accbb125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee41235-d525-4457-e9ed-c7a15dcb3c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count vectorize with 66 features\n",
            "count vectorize with 12109 features\n",
            "6899\n",
            "(6899, 12109)\n"
          ]
        }
      ],
      "source": [
        "# Print out for NepalEQ_df\n",
        "def print_out2(emb, feat, ngram, compared_sentence=0):\n",
        "    print(ngram,\"bag-of-words: \")\n",
        "    print(feat.get_feature_names(), \"\\n\")\n",
        "    print(ngram,\"bag-of-feature: \")\n",
        "    print(test_cv_1gram.vocabulary_, \"\\n\")\n",
        "    print(\"BoW matrix:\")\n",
        "    print(pd.DataFrame(emb.transpose(), index = feat.get_feature_names()).head(), \"\\n\")\n",
        "    print(ngram,\"vector example:\")\n",
        "    print(NepalEQ_df['joined_words'][compared_sentence])\n",
        "    print(emb[compared_sentence], \"\\n\")\n",
        "    \n",
        "NepalEQ_test_corpus = NepalEQ_df['joined_words'][:5].tolist()\n",
        "# print(\"The test corpus: \", test_corpus, \"\\n\")\n",
        "\n",
        "NepalEQ_test_cv_em_1gram, NepalEQ_test_cv_1gram = cv(NepalEQ_test_corpus, ngram=1)\n",
        "# print_out(test_cv_em_1gram, test_cv_1gram, ngram=\"Uni-gram\")\n",
        "\n",
        "# NepalEQ_test_cv_em_2gram, NepalEQ_test_cv_2gram = cv(NepalEQ_test_corpus, ngram=2)\n",
        "# # print_out(test_cv_em_2gram, test_cv_2gram, ngram=\"Bi-gram\")\n",
        "\n",
        "# NepalEQ_test_cv_em_3gram, NepalEQ_test_cv_3gram = cv(NepalEQ_test_corpus, ngram=3)\n",
        "# # print_out(test_cv_em_2gram, test_cv_2gram, ngram=\"Tri-gram\")\n",
        "\n",
        "# implement into the whole NepalEQ_df\n",
        "NepalEQ_df_corpus = NepalEQ_df['joined_words'].tolist()\n",
        "NepalEQ_df_em_1gram, vc_1gram = cv(NepalEQ_df_corpus, 1)\n",
        "# NepalEQ_df_em_2gram, vc_2gram = cv(NepalEQ_df_corpus, 2)\n",
        "# NepalEQ_df_em_3gram, vc_3gram = cv(NepalEQ_df_corpus, 3)\n",
        "\n",
        "print(len(NepalEQ_df_corpus))\n",
        "print(NepalEQ_df_em_1gram.shape)\n",
        "# print(NepalEQ_df_em_2gram.shape)\n",
        "# print(NepalEQ_df_em_3gram.shape)"
      ],
      "id": "accbb125"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "380de590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06e11ea-1871-4b1d-a171-28dd2280a026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count vectorize with 56 features\n",
            "count vectorize with 9587 features\n",
            "6019\n",
            "(6019, 9587)\n"
          ]
        }
      ],
      "source": [
        "# Print out for QueenslandFLD_df\n",
        "def print_out(emb, feat, ngram, compared_sentence=0):\n",
        "    print(ngram,\"bag-of-words: \")\n",
        "    print(feat.get_feature_names(), \"\\n\")\n",
        "    print(ngram,\"bag-of-feature: \")\n",
        "    print(test_cv_1gram.vocabulary_, \"\\n\")\n",
        "    print(\"BoW matrix:\")\n",
        "    print(pd.DataFrame(emb.transpose(), index = feat.get_feature_names()).head(), \"\\n\")\n",
        "    print(ngram,\"vector example:\")\n",
        "    print(QueenslandFLD_df['joined_words'][compared_sentence])\n",
        "    print(emb[compared_sentence], \"\\n\")\n",
        "    \n",
        "QueenslandFLD_test_corpus = QueenslandFLD_df['joined_words'][:5].tolist()\n",
        "# print(\"The test corpus: \", test_corpus, \"\\n\")\n",
        "\n",
        "QueenslandFLD_test_cv_em_1gram, QueenslandFLD_test_cv_1gram = cv(QueenslandFLD_test_corpus, ngram=1)\n",
        "# print_out(QueenslandFLD_test_cv_em_1gram, QueenslandFLD_test_cv_1gram, ngram=\"Uni-gram\")\n",
        "\n",
        "# QueenslandFLD_test_cv_em_2gram, QueenslandFLD_test_cv_2gram = cv(QueenslandFLD_test_corpus, ngram=2)\n",
        "# # print_out(QueenslandFLD_test_cv_em_2gram, QueenslandFLD_test_cv_2gram, ngram=\"Bi-gram\")\n",
        "\n",
        "# QueenslandFLD_test_cv_em_3gram, QueenslandFLD_test_cv_3gram = cv(QueenslandFLD_test_corpus, ngram=3)\n",
        "# # print_out(QueenslandFLD_test_cv_em_3gram, QueenslandFLD_test_cv_3gram, ngram=\"Tri-gram\")\n",
        "\n",
        "# implement into the whole NepalEQ_df\n",
        "QueenslandFLD_df_corpus = QueenslandFLD_df['joined_words'].tolist()\n",
        "QueenslandFLD_df_em_1gram, vc_1gram2 = cv(QueenslandFLD_df_corpus, 1)\n",
        "# QueenslandFLD_df_em_2gram, vc_2gram2 = cv(QueenslandFLD_df_corpus, 2)\n",
        "# QueenslandFLD_df_em_3gram, vc_3gram2 = cv(QueenslandFLD_df_corpus, 3)\n",
        "\n",
        "print(len(QueenslandFLD_df_corpus))\n",
        "print(QueenslandFLD_df_em_1gram.shape)\n",
        "# print(QueenslandFLD_df_em_2gram.shape)\n",
        "# print(QueenslandFLD_df_em_3gram.shape)"
      ],
      "id": "380de590"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "947ebc01"
      },
      "source": [
        "### Term Frequency-Inverse Document Frequency (TF-IDF)"
      ],
      "id": "947ebc01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7d43e62"
      },
      "outputs": [],
      "source": [
        "def TFIDF(data, ngram = 1, MAX_NB_WORDS = 75000):\n",
        "    tfidf_x = TfidfVectorizer(ngram_range = (ngram, ngram), max_features = MAX_NB_WORDS)\n",
        "    emb = tfidf_x.fit_transform(data).toarray()\n",
        "    print(\"tf-idf with\", str(np.array(emb).shape[1]), \"features\")\n",
        "    return emb, tfidf_x"
      ],
      "id": "f7d43e62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eb79ac9",
        "outputId": "fcb3417c-175a-44ec-ecfc-b201af3cce52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf with 66 features\n",
            "tf-idf with 12109 features\n",
            "6899\n",
            "(6899, 12109)\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF for NepalEQ_df\n",
        "NepalEQ_test_corpus = NepalEQ_df['joined_words'][:5].tolist()\n",
        "#print(\"The test corpus: \", test_corpus, \"\\n\")\n",
        "\n",
        "NepalEQ_test_tfidf_em_1gram, NepalEQ_test_tfidf_1gram = TFIDF(NepalEQ_test_corpus, ngram=1)\n",
        "#print_out2(NepalEQ_test_tfidf_em_1gram, NepalEQ_test_tfidf_1gram, ngram=\"Uni-gram\")\n",
        "\n",
        "# NepalEQ_test_tfidf_em_2gram, NepalEQ_test_tfidf_2gram = TFIDF(NepalEQ_test_corpus, ngram=2)\n",
        "# #print_out2(NepalEQ_test_tfidf_em_2gram, NepalEQ_test_tfidf_2gram, ngram=\"Bi-gram\")\n",
        "\n",
        "# NepalEQ_test_tfidf_em_3gram, NepalEQ_test_tfidf_3gram = TFIDF(NepalEQ_test_corpus, ngram=3)\n",
        "# #print_out2(NepalEQ_test_tfidf_em_3gram, NepalEQ_test_tfidf_3gram, ngram=\"Tri-gram\")\n",
        "\n",
        "# implement into the whole dataset\n",
        "NepalEQ_df_corpus = NepalEQ_df['joined_words'].tolist()\n",
        "NepalEQ_df_tfidf_1gram, tfidf_1gram = TFIDF(NepalEQ_df_corpus, 1)\n",
        "# NepalEQ_df_tfidf_2gram, tfidf_2gram = TFIDF(NepalEQ_df_corpus, 2)\n",
        "# NepalEQ_df_tfidf_3gram, tfidf_3gram = TFIDF(NepalEQ_df_corpus, 3)\n",
        "\n",
        "print(len(NepalEQ_df_corpus))\n",
        "print(NepalEQ_df_tfidf_1gram.shape)\n",
        "# print(NepalEQ_df_tfidf_2gram.shape)\n",
        "# print(NepalEQ_df_tfidf_3gram.shape)"
      ],
      "id": "9eb79ac9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d35aa49",
        "outputId": "6c92438b-ebb1-4071-9db7-365a9d2616fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf with 56 features\n",
            "tf-idf with 9587 features\n",
            "6019\n",
            "(6019, 9587)\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF for QueenslandFLD_df\n",
        "QueenslandFLD_test_corpus = QueenslandFLD_df['joined_words'][:5].tolist()\n",
        "#print(\"The test corpus: \", test_corpus, \"\\n\")\n",
        "\n",
        "QueenslandFLD_test_tfidf_em_1gram, QueenslandFLD_test_tfidf_1gram = TFIDF(QueenslandFLD_test_corpus, ngram=1)\n",
        "#print_out(QueenslandFLD_test_tfidf_em_1gram, QueenslandFLD_test_tfidf_1gram, ngram=\"Uni-gram\")\n",
        "\n",
        "# QueenslandFLD_test_tfidf_em_2gram, QueenslandFLD_test_tfidf_2gram = TFIDF(QueenslandFLD_test_corpus, ngram=2)\n",
        "# #print_out(QueenslandFLD_test_tfidf_em_2gram, QueenslandFLD_test_tfidf_2gram, ngram=\"Bi-gram\")\n",
        "\n",
        "# QueenslandFLD_test_tfidf_em_3gram, QueenslandFLD_test_tfidf_3gram = TFIDF(QueenslandFLD_test_corpus, ngram=3)\n",
        "# #print_out(NepalEQ_test_tfidf_em_3gram, NepalEQ_test_tfidf_3gram, ngram=\"Tri-gram\")\n",
        "\n",
        "# implement into the whole dataset\n",
        "QueenslandFLD_df_corpus = QueenslandFLD_df['joined_words'].tolist()\n",
        "QueenslandFLD_df_tfidf_1gram, tfidf_1gram2 = TFIDF(QueenslandFLD_df_corpus, 1)\n",
        "# QueenslandFLD_df_tfidf_2gram, tfidf_2gram2 = TFIDF(QueenslandFLD_df_corpus, 2)\n",
        "# QueenslandFLD_df_tfidf_3gram, tfidf_3gram2 = TFIDF(QueenslandFLD_df_corpus, 3)\n",
        "\n",
        "print(len(QueenslandFLD_df_corpus))\n",
        "print(QueenslandFLD_df_tfidf_1gram.shape)\n",
        "# print(QueenslandFLD_df_tfidf_2gram.shape)\n",
        "# print(QueenslandFLD_df_tfidf_3gram.shape)"
      ],
      "id": "6d35aa49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1148ff0"
      },
      "source": [
        "### Word2Vec"
      ],
      "id": "b1148ff0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "910c22be"
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "word2vec_path = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "# we only load 200k most common words from Google News corpus\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=200000)"
      ],
      "id": "910c22be"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Z-bgLTTqoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b9d024-6a27-419c-933e-66afbd72a056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.74649847\n",
            "0.8099379\n"
          ]
        }
      ],
      "source": [
        "# Compare the similarity between \"cat\" vs. \"kitten\" and \"cat\" vs. \"cats\"\n",
        "\n",
        "print(word2vec_model.similarity('cat', 'kitten'))\n",
        "print(word2vec_model.similarity('cat', 'cats'))"
      ],
      "id": "S4Z-bgLTTqoY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VwiM8ddTxrx"
      },
      "outputs": [],
      "source": [
        "def get_average_vec(tokens_list, vector, generate_missing=False, k=300):\n",
        "    \"\"\"\n",
        "        Calculate average embedding value of sentence from each word vector\n",
        "    \"\"\"\n",
        "    \n",
        "    if len(tokens_list)<1:\n",
        "        return np.zeros(k)\n",
        "    \n",
        "    if generate_missing:\n",
        "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "    else:\n",
        "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    \n",
        "    length = len(vectorized)\n",
        "    summed = np.sum(vectorized, axis=0)\n",
        "    averaged = np.divide(summed, length)\n",
        "    return averaged\n",
        "\n",
        "def get_embeddings(vectors, text, generate_missing=False, k=300):\n",
        "    \"\"\"\n",
        "        create the sentence embedding\n",
        "    \"\"\"\n",
        "    embeddings = text.apply(lambda x: get_average_vec(x, vectors, generate_missing=generate_missing, k=k))\n",
        "    return list(embeddings)"
      ],
      "id": "0VwiM8ddTxrx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9314e3aT5cS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b91f64-a9c0-457b-e797-d95e663648d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6899 300\n",
            "The sentence: \"rt anupkaphle #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plan lot of referen\" got embedding values: \n",
            "[-0.12967104  0.09333755 -0.01329457  0.11189131 -0.04398554  0.01486761\n",
            " -0.07004385 -0.02966679 -0.03154547  0.01759292 -0.04088751 -0.06536634\n",
            " -0.15724714  0.03127959 -0.09672778  0.08136264  0.08919363  0.13743638\n",
            " -0.01433586  0.02128092 -0.19123424 -0.03023541  0.08887528  0.00675672\n",
            " -0.07978081  0.02013524 -0.18579656  0.05401195 -0.02749171 -0.02586943\n",
            " -0.00714539  0.01675403 -0.072719   -0.08760857 -0.10657201  0.06748315\n",
            " -0.16937949  0.07192438 -0.04125468  0.05902608 -0.02513308 -0.05098378\n",
            "  0.0348594   0.06829279  0.04072293 -0.02002736 -0.03920029 -0.13438092\n",
            " -0.1003418   0.07520086 -0.13920177  0.19218306 -0.03951564  0.16987564\n",
            "  0.05048024  0.11500474 -0.12705855 -0.08820574  0.00082952 -0.13443456\n",
            " -0.0995562  -0.06259479 -0.14324674 -0.03739343 -0.04354419 -0.15479255\n",
            " -0.08691175  0.09770434 -0.0487583   0.0435976   0.01070705 -0.06038596\n",
            "  0.04202271 -0.00153559 -0.01819952 -0.00346236  0.11125322  0.01393544\n",
            "  0.01457723 -0.06745679 -0.11242676 -0.01049019 -0.02925792 -0.00360847\n",
            "  0.10929963  0.05922075 -0.0032025   0.16350671  0.01749339  0.03612356\n",
            "  0.01639164  0.00848019 -0.03032615 -0.09822267  0.02886408  0.08459588\n",
            " -0.06947373  0.07327779  0.19904593 -0.03419402 -0.05988104  0.00385215\n",
            " -0.06363747  0.00310678 -0.04048457  0.12267512 -0.06338224  0.03463953\n",
            "  0.00991081  0.02748547 -0.10535778 -0.14376091 -0.02762436 -0.03010559\n",
            "  0.039313    0.12661558  0.06178995 -0.03582232 -0.01598959 -0.0245381\n",
            "  0.08900036  0.06368464 -0.01568432  0.03689298  0.10234116 -0.14498901\n",
            " -0.08472026 -0.02334225  0.03290581  0.08800593 -0.05635764 -0.02615715\n",
            " -0.0546519  -0.04066698 -0.12425082  0.06036134 -0.01686744  0.02516498\n",
            "  0.1934759   0.10184456  0.15687145 -0.06086349  0.03157506 -0.03605143\n",
            " -0.05721121 -0.07766741 -0.03252804  0.12472072 -0.02908233  0.01061006\n",
            "  0.04279905 -0.22784239 -0.03730235 -0.03531346 -0.08214407 -0.0936848\n",
            "  0.06290297  0.14716686 -0.02086651 -0.01879004  0.00580666  0.0670351\n",
            " -0.00884154 -0.00587024 -0.00155917 -0.02184642  0.13015562  0.01702916\n",
            " -0.07318502  0.08064455 -0.06978677 -0.07425297 -0.04260069 -0.04839279\n",
            " -0.01671358  0.17423873  0.19826438 -0.17565548  0.00377956 -0.05894251\n",
            " -0.00176262  0.01581456  0.02648622 -0.04783769 -0.02230558  0.04847602\n",
            " -0.04581058  0.06552297 -0.02186261  0.05000513  0.09864067 -0.04746038\n",
            " -0.20035807 -0.01281137  0.09423088  0.01848533 -0.04939143 -0.00976609\n",
            "  0.05441955 -0.05650006 -0.08337032 -0.00203219 -0.15586344 -0.10610869\n",
            "  0.05654445 -0.06626707 -0.02015362  0.08164562 -0.03371661  0.13048669\n",
            "  0.12356706  0.07552453 -0.11301307  0.01424061 -0.06025002  0.0599139\n",
            "  0.12901722 -0.03991407 -0.12640982  0.0058418  -0.08696308  0.08908543\n",
            "  0.06702215 -0.0205781  -0.00367922 -0.06172134  0.05380943  0.03601999\n",
            "  0.00347036 -0.11596772  0.00551816 -0.039044   -0.07172978  0.00595463\n",
            " -0.00528047  0.01040097  0.04662103  0.0761109   0.06014645  0.07196045\n",
            "  0.07055918  0.05566961  0.20651153 -0.04632268  0.00216582  0.06314526\n",
            " -0.11071222  0.1045338   0.035847   -0.06411223  0.04124302 -0.00587394\n",
            "  0.04180261  0.07697215 -0.02004727 -0.10497642 -0.04423731  0.04980839\n",
            "  0.03059826 -0.06497331  0.05127797 -0.01233933  0.07567805 -0.01536051\n",
            " -0.0689473   0.00494708  0.00866144  0.00700933 -0.00816183 -0.03494101\n",
            " -0.06361354 -0.013279    0.02583729  0.01632783  0.05259936 -0.05551702\n",
            " -0.12773456 -0.09646884 -0.07549124  0.0445048  -0.0733023   0.12154504\n",
            " -0.00391319  0.00446551  0.0097284   0.04641539 -0.01588764 -0.01348738\n",
            " -0.04419778 -0.0326182   0.05264005 -0.02030621 -0.08408009  0.06636833\n",
            " -0.03125    -0.12672748 -0.07078136 -0.0227245  -0.08415823  0.12466939]\n"
          ]
        }
      ],
      "source": [
        "# word2vec embedding for NepalEQ_df\n",
        "NepalEQ_df_embeddings_word2vec = get_embeddings(word2vec_model, NepalEQ_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(NepalEQ_df_embeddings_word2vec), len(NepalEQ_df_embeddings_word2vec[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % NepalEQ_df['joined_words'][0])\n",
        "print(NepalEQ_df_embeddings_word2vec[0])"
      ],
      "id": "h9314e3aT5cS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0hpjrKbUa1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c050983a-2d37-42b8-b413-fe30837ccbb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6019 300\n",
            "The sentence: \"i just though about the night i went clubbing with mikal and i cried\" got embedding values: \n",
            "[-1.63563448e-01  7.50436222e-02 -9.85448501e-03  1.10333611e-01\n",
            " -7.37286736e-02  1.06757669e-02 -8.07149550e-02 -6.53309542e-02\n",
            " -2.02914967e-02  7.56387150e-03 -4.45586934e-02 -9.07000373e-02\n",
            " -1.93838680e-01  6.78079269e-03 -9.35561236e-02  6.82624368e-02\n",
            "  2.79763166e-02  1.38955509e-01 -1.81637932e-02 -1.38536341e-02\n",
            " -1.84408749e-01 -2.87531684e-02  1.03880714e-01 -6.31399716e-03\n",
            " -5.34367281e-02  3.72934762e-02 -2.33879538e-01  2.65915815e-02\n",
            " -8.75854492e-03 -9.51430377e-05  2.63501336e-02  2.92273129e-02\n",
            " -1.97516049e-02 -7.43848015e-02 -1.30762437e-01  8.94642998e-02\n",
            " -1.83158875e-01  1.07366225e-01 -4.87558140e-02  7.45957318e-02\n",
            " -1.99827306e-02 -4.13028493e-02  1.04440128e-01  7.65748865e-02\n",
            "  4.69158958e-02 -3.87151382e-02  1.08041202e-02 -1.34212718e-01\n",
            " -7.94821347e-02  3.47684972e-02 -1.17438821e-01  1.69404871e-01\n",
            " -2.98982508e-02  2.28937486e-01  3.77556296e-02  6.99032054e-02\n",
            " -9.55523323e-02 -6.63250194e-02 -2.58851893e-02 -1.23337690e-01\n",
            " -8.98877312e-02 -4.66667624e-02 -1.59826840e-01 -3.93044808e-02\n",
            " -2.08625793e-02 -1.91560633e-01 -8.18279491e-02  8.19576488e-02\n",
            " -4.57799575e-02  1.65423225e-02  1.49877212e-02 -3.34616268e-02\n",
            "  5.93656652e-03 -1.43046660e-02 -5.00160666e-02 -3.91091739e-02\n",
            "  7.73925781e-02  2.20651066e-02 -3.40944178e-03 -7.54897174e-02\n",
            " -1.37935863e-01 -1.66949104e-04 -3.47702363e-02 -8.88959099e-03\n",
            "  9.17681526e-02  7.18724868e-02  3.31025965e-03  1.91867604e-01\n",
            "  7.74159151e-04  4.02903837e-02  3.47990148e-03  4.53993853e-02\n",
            " -1.37616326e-02 -1.03486903e-01  5.21231259e-02  9.88509234e-02\n",
            " -8.11686796e-02  4.71029843e-02  2.04442641e-01 -1.26971077e-02\n",
            " -8.96355124e-02 -3.01109763e-02 -3.29589844e-02  1.47202436e-03\n",
            " -7.15996237e-02  1.09568876e-01 -5.16357422e-02  3.34535487e-02\n",
            " -1.58906824e-02  1.10343484e-02 -1.26192878e-01 -1.32304023e-01\n",
            " -3.03220188e-02 -1.45499286e-02  7.90288589e-02  1.11719468e-01\n",
            "  4.91817699e-02 -6.54503317e-02 -2.20045202e-02 -3.92967673e-02\n",
            "  1.02797564e-01  5.21545410e-02 -1.17295209e-02  2.54785874e-02\n",
            "  1.11654843e-01 -1.25832950e-01 -7.32884127e-02 -4.90166159e-03\n",
            "  5.60643813e-02  5.39726931e-02 -9.07215792e-02 -1.63484461e-02\n",
            " -5.21271650e-02 -2.89764404e-02 -1.47253934e-01  4.15237651e-02\n",
            " -6.31013758e-02  7.01724782e-03  1.98055492e-01  1.03535820e-01\n",
            "  1.49832333e-01 -6.03596182e-02  4.60555133e-02 -4.00354722e-02\n",
            " -4.99123966e-02 -5.09392233e-02 -6.16805133e-02  1.22152889e-01\n",
            " -3.51257324e-02  3.57520160e-02  6.58380845e-02 -2.47077493e-01\n",
            " -5.72446935e-02 -2.65879912e-02 -9.01469062e-02 -5.31490550e-02\n",
            "  6.24739703e-02  1.40018239e-01 -3.18677566e-02 -1.77930944e-02\n",
            "  2.10535386e-02  1.06036018e-01  1.00326538e-02  1.77989287e-02\n",
            " -1.76346723e-02 -7.15803259e-02  1.18765438e-01  4.87161524e-02\n",
            " -8.46037023e-02  7.46361228e-02 -1.11662023e-01 -6.09256520e-02\n",
            " -2.49561983e-02 -4.52055090e-02 -1.02007249e-02  1.54465619e-01\n",
            "  2.07142549e-01 -1.66525448e-01  4.57431569e-02 -9.88069422e-02\n",
            "  1.59194049e-02  4.87027168e-02  3.77230925e-02 -1.95492015e-02\n",
            " -9.00089040e-03  8.39350083e-02 -4.36841179e-02  6.04645224e-02\n",
            " -2.55916820e-02  1.90292807e-02  9.91466747e-02 -1.08193790e-02\n",
            " -1.89323874e-01 -1.82670144e-02  1.03761561e-01  4.36760398e-02\n",
            " -6.76422119e-02 -1.42732508e-02  6.37700698e-02 -1.00311279e-01\n",
            " -9.91596895e-02  2.59300681e-02 -1.61475686e-01 -1.10301298e-01\n",
            "  4.05291389e-02 -7.59829353e-02 -5.51721909e-02  7.00306612e-02\n",
            " -2.80328638e-02  1.38693417e-01  9.50667437e-02  7.79800415e-02\n",
            " -1.26231698e-01 -2.87637150e-02 -1.02111816e-01 -1.18480009e-03\n",
            "  1.10362333e-01 -4.07670526e-02 -1.20235668e-01  7.28831572e-03\n",
            " -1.31703096e-01  1.29000495e-01  6.57205021e-02  1.12538057e-02\n",
            "  2.19439338e-02 -7.62804817e-02  5.87840361e-02  6.55248305e-02\n",
            " -2.26897071e-02 -1.07133753e-01  4.89039702e-02 -3.09447120e-02\n",
            " -6.09379796e-02  3.49022360e-03  9.33837891e-03  2.48133435e-02\n",
            "  3.69262695e-02  6.85993082e-02  8.34673713e-02  7.87034876e-02\n",
            "  7.61346256e-02  9.58826402e-02  2.16972800e-01 -4.55088896e-02\n",
            " -3.63730262e-02  8.78964592e-02 -1.44209020e-01  1.44752951e-01\n",
            "  2.13703969e-02 -8.82220549e-02  1.21240952e-01  2.30223712e-02\n",
            "  4.48680205e-02  7.27213691e-02  9.15437586e-03 -8.91974954e-02\n",
            " -1.96106855e-02  4.67349782e-02  3.46145630e-02 -3.77143411e-02\n",
            "  5.26652617e-02 -2.45636772e-02  3.84988224e-02 -5.78173469e-03\n",
            " -8.29943489e-02  1.63681928e-02 -2.71785960e-03 -1.37463738e-03\n",
            " -2.13380701e-02 -9.23906214e-02 -4.43965687e-02 -3.65510828e-02\n",
            "  5.38599351e-02  5.25737089e-02  6.90630744e-02 -7.11571189e-02\n",
            " -1.17518705e-01 -1.11837948e-01 -8.56727151e-02  5.88989258e-02\n",
            " -4.93693632e-02  1.36923397e-01  2.48291913e-02  3.71699614e-02\n",
            " -1.81386611e-02  5.09670482e-02  1.65795719e-02 -3.48932603e-02\n",
            " -4.53688678e-02 -2.90742762e-02  4.77546243e-02  4.30746639e-02\n",
            " -4.54615425e-02  6.69681325e-02 -2.10661047e-02 -1.28015855e-01\n",
            " -1.12604478e-01 -3.28387092e-02 -9.30301442e-02  9.85466452e-02]\n"
          ]
        }
      ],
      "source": [
        "# word2vec embedding for QueenslandFLD_df\n",
        "QueenslandFLD_df_embeddings_word2vec = get_embeddings(word2vec_model, QueenslandFLD_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(QueenslandFLD_df_embeddings_word2vec), len(QueenslandFLD_df_embeddings_word2vec[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % QueenslandFLD_df['joined_words'][0])\n",
        "print(QueenslandFLD_df_embeddings_word2vec[0])"
      ],
      "id": "m0hpjrKbUa1d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuGMu8NVVSQ_"
      },
      "source": [
        "### Global Vectors for Word Representation (GloVe):"
      ],
      "id": "YuGMu8NVVSQ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LuSBheaUzpX"
      },
      "outputs": [],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_input_file = \"/content/drive/MyDrive/glove/glove.6B.300d.txt\"\n",
        "word2vec_output_file = \"glove.6B.100d.txt.word2vec\"\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "\n",
        "# we only load 200k most common words from Google New corpus \n",
        "glove_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False, limit=200000) \n"
      ],
      "id": "2LuSBheaUzpX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXSLD4RQxi56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1f38a8-0b6a-4878-eefb-2161d351bea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43046176\n",
            "0.68158364\n"
          ]
        }
      ],
      "source": [
        "# Compare the similarity between \"cat\" vs. \"kitten\" and \"cat\" vs. \"cats\" from GloVe\n",
        "\n",
        "print(glove_model.similarity('cat', 'kitten'))\n",
        "print(glove_model.similarity('cat', 'cats'))"
      ],
      "id": "pXSLD4RQxi56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpysiNfmx6_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b09dac1-05b0-4300-9032-62a20febb033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6899 300\n",
            "The sentence: \"rt anupkaphle #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plan lot of referen\" got embedding values: \n",
            "[-2.28495274e-01 -6.08209594e-03 -2.15541902e-01 -3.94118740e-02\n",
            " -5.11049563e-01 -6.87474010e-03 -2.49461290e-02  1.65043709e-01\n",
            " -2.87330804e-01 -9.65558717e-01  1.99469061e-02  4.87846921e-02\n",
            " -2.94508145e-01  7.04633225e-02 -3.48408861e-02 -1.51335466e-01\n",
            " -2.39974160e-01  3.09178506e-01  1.62798942e-01 -1.48918035e-02\n",
            " -6.54065627e-02 -1.36595992e-01 -4.97086888e-02  5.38109673e-02\n",
            " -1.04650691e-01  1.33385234e-01  1.36464177e-01  1.80182668e-01\n",
            "  3.42624088e-01 -3.47929564e-01 -9.67238854e-02  3.12049121e-01\n",
            " -2.19132944e-01 -1.22670792e-01 -6.06338107e-01  2.52418038e-02\n",
            "  2.72592938e-01 -4.19366895e-01 -1.88869530e-01  1.20775761e-01\n",
            " -7.62118774e-02  6.64482197e-02 -4.71248429e-01  5.14597980e-01\n",
            " -2.43327927e-01 -2.27424684e-01  1.38591626e-01 -8.83835115e-02\n",
            "  2.78771353e-02  3.60399136e-02  9.42300536e-02  1.41306876e-01\n",
            " -9.01429957e-02  8.73275990e-02  7.29386175e-03  2.63279026e-01\n",
            "  6.34193185e-02 -2.10435155e-02  2.02467276e-02 -3.54623885e-01\n",
            "  3.96871410e-01  1.60429831e-01  1.14955754e-01  1.20381532e-01\n",
            " -8.12079261e-02 -9.98868735e-02 -1.49798801e-01  1.08429309e-01\n",
            "  2.47495577e-01 -1.58250536e-01 -2.38772912e-01  3.46512936e-01\n",
            "  1.54027885e-01  2.24546044e-01 -3.25876208e-01 -5.13025972e-02\n",
            "  1.83424819e-01  3.06884597e-02 -9.82718626e-02 -3.17836508e-02\n",
            " -5.71791067e-02  1.01920472e-01  1.23815095e-01 -3.49273190e-01\n",
            "  2.08084666e-01  8.34693810e-03 -4.68834170e-02  3.06744464e-01\n",
            "  1.12998609e-01 -1.04331596e-01  4.27714137e-02  1.20931703e-01\n",
            " -2.81976562e-01 -4.37434317e-01  3.34328513e-01  3.62436308e-02\n",
            " -9.06619527e-02 -1.90325305e-01  1.87054189e-01 -3.84953856e-01\n",
            " -1.80099646e-01  2.58390433e-02 -2.36469594e-02  1.13759115e-01\n",
            " -1.55622611e-01 -2.80637563e-01  5.24624150e-02  2.29737461e-01\n",
            "  8.80625092e-02  2.78117771e-02 -4.87225603e-02 -8.71565832e-02\n",
            "  1.49181686e-01  1.27473228e-01 -5.78180416e-02 -2.84830321e-02\n",
            " -1.05822273e-01  1.84228469e-01  6.32254697e-02 -2.08261298e-01\n",
            "  3.50660704e-01 -1.52507317e-01  8.95369505e-02 -2.14515676e-01\n",
            "  5.14513003e-02  6.78944877e-02 -2.25178842e-02  1.03095017e-02\n",
            " -1.94053280e-01 -5.10862514e-02 -7.06242124e-02 -7.43119828e-02\n",
            " -3.75436577e-01  1.22148492e-01  3.87839224e-02 -2.09232762e-01\n",
            "  3.96223384e-03 -1.20103182e-01  2.74539782e-01 -7.16006909e-02\n",
            " -1.64557122e-01  2.58852288e-01  1.04736165e-01 -1.02677408e-01\n",
            " -2.51223702e-01 -1.09819222e-01 -1.92915900e-01 -2.07594371e-01\n",
            "  2.98247346e-01 -6.96951551e-02  3.22996389e-01 -1.97311846e-01\n",
            "  2.61885968e-02 -1.60095918e-01  1.55863492e-01 -5.98600974e-02\n",
            "  3.04082466e-01  5.48752026e-02  2.75790621e-02 -8.94345116e-02\n",
            " -2.78585815e-03 -1.00205627e-01 -2.11268753e-01 -3.15078821e-02\n",
            " -2.29692907e-01  2.12562070e-01 -4.27055556e-02  8.85689095e-02\n",
            " -9.98418695e-02  1.87604882e-01  1.07888766e-01  2.78990843e-01\n",
            " -1.37254991e-01  4.56053389e-01 -2.50888165e-02 -5.15606727e-02\n",
            " -1.31438105e-01 -1.90912183e-01  1.61706517e-01  2.52317198e-01\n",
            " -2.10603039e-01  2.42686183e-01 -1.99556706e-01 -1.79686377e-01\n",
            " -2.62802531e-01 -3.18463079e-01 -2.01103409e-01  1.94420484e-01\n",
            "  2.55374284e-01  2.47614726e-01  3.75645563e-01  1.31522737e-01\n",
            "  1.02343949e-01  2.98344289e-01 -2.31582490e-01  1.07504624e-01\n",
            "  2.20949204e-01 -6.01074547e-02 -1.78658606e-01 -2.49068124e-01\n",
            "  6.75673331e-01 -7.92127809e-02  2.39927895e-01  3.17474876e-01\n",
            "  1.56688857e-01 -3.01603051e-01 -3.65196516e-01  1.86413517e-01\n",
            "  1.90653314e-01 -2.87744251e-01 -4.66589673e-01 -9.02570322e-02\n",
            " -1.49837719e-01  2.93673481e-01 -4.45656881e-01  6.25026663e-02\n",
            "  2.02032764e-01 -4.59751753e-02 -1.83627499e-01 -3.12234972e-01\n",
            " -5.06995075e-02  1.50421513e-01  1.10789899e-01  1.52595906e-01\n",
            "  7.10381073e-02 -5.43728234e-02  4.68314266e-02  9.67498707e-02\n",
            " -3.83838694e-03  2.04636918e-01 -2.81153425e-02  3.25397881e-01\n",
            " -1.64489988e-02 -2.42063302e-01  3.06956376e-01 -1.65497207e-04\n",
            " -1.02653688e-01 -4.67440542e-02  9.25848338e-02  1.97335401e-01\n",
            " -1.23766406e-01 -2.96406378e-01  3.49781681e-02  4.34461374e-02\n",
            " -1.16944235e-01 -1.28559016e-02  1.30720380e-01 -1.09005878e-01\n",
            " -3.83292428e-02  1.42278810e-01 -1.58746881e-01  1.96424980e-01\n",
            " -2.08536528e-01 -2.34981391e-01 -1.41300122e-01 -1.23910972e-01\n",
            "  5.75522755e-02 -2.95796660e-01  9.12815923e-02  1.02011409e-01\n",
            "  3.65528900e-01 -2.94051854e-01 -8.35639465e-02 -5.96739337e-02\n",
            " -9.22164998e-02 -7.52128252e-02  3.75433255e-01  2.02918692e-01\n",
            "  2.11043653e-01  4.80650227e-01 -1.42830485e-01 -3.17374029e-01\n",
            "  1.98720578e-01 -3.49615036e-01 -1.81432323e-01  3.04335155e-01\n",
            " -6.55987285e-01 -1.24132882e-02 -5.00427902e-02  1.62920224e-02\n",
            " -2.32740125e-01 -2.43147523e-01 -4.11889069e-01 -1.76836510e-01\n",
            "  7.60765815e-02 -4.13925445e-02 -7.30472729e-02  1.22143701e-01\n",
            "  2.17938149e-01  2.06141943e-01 -1.30813451e-01  1.87977310e-03\n",
            " -1.24031716e-01 -6.31110602e-02  9.75573033e-02  1.29061894e-01\n",
            "  4.02721944e-01 -4.73931106e-01 -1.27604558e-01  1.33317687e-01]\n"
          ]
        }
      ],
      "source": [
        "# GloVe embedding for NepalEQ_df\n",
        "NepalEQ_df_embeddings_glove = get_embeddings(glove_model, NepalEQ_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(NepalEQ_df_embeddings_glove), len(NepalEQ_df_embeddings_glove[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % NepalEQ_df['joined_words'][0])\n",
        "print(NepalEQ_df_embeddings_glove[0])"
      ],
      "id": "DpysiNfmx6_d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1lKLssWyWlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e949d690-9987-4d72-9c31-a9b92a609663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6019 300\n",
            "The sentence: \"i just though about the night i went clubbing with mikal and i cried\" got embedding values: \n",
            "[-0.180241    0.05367574 -0.22297876 -0.06396813 -0.50907456 -0.03861293\n",
            " -0.01607928  0.18043071 -0.28707592 -0.97813588  0.04812866 -0.02829128\n",
            " -0.3372479   0.09836832 -0.0438285  -0.08034226 -0.22341007  0.14967854\n",
            "  0.16738716 -0.06665697 -0.00550996 -0.07034315 -0.03217519 -0.00369645\n",
            " -0.10867484  0.05491472  0.12675622  0.14748965  0.21412467 -0.27017695\n",
            " -0.13606109  0.25332606 -0.2670711  -0.11544512 -0.64905941  0.05140057\n",
            "  0.17464412 -0.36758426 -0.14558212  0.12436544 -0.11094847 -0.06671769\n",
            " -0.45691253  0.36810354 -0.18775615 -0.20758322  0.20938235 -0.16841442\n",
            "  0.00454974 -0.00662629  0.02318772  0.1114213  -0.05654474  0.06435995\n",
            " -0.02248227  0.29823227  0.168935   -0.02039458  0.07767013 -0.24694474\n",
            "  0.45494457  0.21746578  0.01598245  0.06547459 -0.0469127  -0.0907941\n",
            " -0.21906404  0.10436953  0.22956766 -0.13917463 -0.15885296  0.37994023\n",
            "  0.12484004  0.29392435 -0.31904265 -0.07479363  0.20020912  0.0311605\n",
            " -0.13349197 -0.07093551 -0.0974516   0.06155688  0.15352217 -0.33096632\n",
            "  0.09446462  0.02342385 -0.13191838  0.32979577  0.13715607 -0.08846837\n",
            "  0.07493164  0.15481414 -0.24697343 -0.35541343  0.32782735  0.12074699\n",
            " -0.07394653 -0.15100264  0.14296307 -0.37386962 -0.20407856 -0.06641789\n",
            " -0.05452607  0.03605396 -0.20682793 -0.20007662  0.09681435  0.22579137\n",
            "  0.00988656  0.1073062  -0.11700414 -0.09275331  0.11971367  0.01399033\n",
            " -0.05278483 -0.06631654 -0.12362444  0.12775808  0.0575241  -0.15464182\n",
            "  0.28412534 -0.10528607  0.21605185 -0.22913765  0.02505707  0.09714185\n",
            " -0.0052035   0.04217459 -0.16887652  0.03042284 -0.09448312 -0.04857704\n",
            " -0.19019019  0.04947991  0.00851832 -0.16786721 -0.0453283  -0.1664649\n",
            "  0.14596994 -0.053722   -0.12163357  0.3249847   0.15234415 -0.040519\n",
            " -0.21301935 -0.02451864 -0.24860884 -0.21691385  0.24916272 -0.03708069\n",
            "  0.10949061 -0.12333931 -0.02898679 -0.15195487  0.12320778 -0.08535441\n",
            "  0.26115758  0.0735857   0.06579766 -0.14829275 -0.00168002 -0.16261679\n",
            " -0.23924383  0.01254173 -0.2161986   0.27168656  0.00112785  0.26248051\n",
            " -0.02604686  0.12623529  0.19531711  0.22623826 -0.0572125   0.28613663\n",
            " -0.09894717 -0.07063476 -0.12569192 -0.07125166  0.11388     0.26812\n",
            " -0.21835104  0.1978675  -0.15373578 -0.27509687 -0.24193412 -0.18296828\n",
            " -0.2366147   0.28923881  0.25396528  0.28260981  0.42058575  0.10733235\n",
            "  0.12990543  0.24223007 -0.17002101  0.02268591  0.14245896 -0.06896079\n",
            " -0.13750798 -0.23648433  0.76343559 -0.11735385  0.20549245  0.27214005\n",
            "  0.14800869 -0.16010907 -0.35569532  0.09000334  0.23942509 -0.26605429\n",
            " -0.4638929  -0.07274669 -0.19915556  0.24731859 -0.43775442  0.10673138\n",
            "  0.17462309 -0.07304976 -0.12225765 -0.36149207 -0.04097548  0.09974272\n",
            "  0.06554254  0.16532259  0.06904789 -0.02735046  0.09400562  0.06703775\n",
            " -0.07735816  0.20816039  0.00301252  0.29836204  0.00968814 -0.30086646\n",
            "  0.2055018   0.09489156 -0.0773748  -0.08115277  0.10563532  0.21559278\n",
            " -0.01053086 -0.28516678 -0.00713079  0.09857659 -0.09926847 -0.04089107\n",
            "  0.07948717 -0.0979947  -0.02362335  0.08342241 -0.0872181   0.16358708\n",
            " -0.17206067 -0.17420996 -0.12190344 -0.03016554  0.04156162 -0.30661529\n",
            " -0.00613042  0.00677244  0.35102663 -0.26189491 -0.05842329  0.06758255\n",
            " -0.04327032 -0.06319312  0.26392177  0.11578242  0.15474841  0.53719059\n",
            " -0.11871414 -0.24655771  0.16241621 -0.3118146  -0.15989013  0.28965705\n",
            " -0.63707087  0.00550451 -0.09792372  0.04443493 -0.21580169 -0.23782719\n",
            " -0.28280968 -0.21189032  0.0754274   0.04072269 -0.11031329  0.10744605\n",
            "  0.10778821  0.12516521 -0.12224928 -0.01532916 -0.16067237 -0.11283071\n",
            "  0.10078438  0.04633235  0.54044029 -0.44966135  0.00853688  0.13958269]\n"
          ]
        }
      ],
      "source": [
        "# GloVe embedding for QueenslandFLD_df\n",
        "QueenslandFLD_df_embeddings_glove = get_embeddings(glove_model, QueenslandFLD_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(QueenslandFLD_df_embeddings_glove), len(QueenslandFLD_df_embeddings_glove[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % QueenslandFLD_df['joined_words'][0])\n",
        "print(QueenslandFLD_df_embeddings_glove[0])"
      ],
      "id": "a1lKLssWyWlS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70tSeQNPy9jR"
      },
      "source": [
        "### FastText"
      ],
      "id": "70tSeQNPy9jR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlIq8uBEym3z"
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "fasttext_path = \"/content/drive/MyDrive/wiki-news-300d-1M.vec\"\n",
        "fasttext_model = gensim.models.KeyedVectors.load_word2vec_format(fasttext_path, binary=False, limit=200000)"
      ],
      "id": "qlIq8uBEym3z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQJYwUWYzUC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff8e432-df35-4a9e-962f-21af66c34a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7353649\n",
            "0.85528094\n"
          ]
        }
      ],
      "source": [
        "print(fasttext_model.similarity('cat', 'kitten'))\n",
        "print(fasttext_model.similarity('cat', 'cats'))"
      ],
      "id": "oQJYwUWYzUC2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hj87cXozouz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53d7531-2024-4764-919e-90c60440767b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6899 300\n",
            "The sentence: \"rt anupkaphle #nepal's prime minister addressed the country for st time since earthquake on saturday no concrete plan lot of referen\" got embedding values: \n",
            "[-9.07727273e-02  1.13992423e-02 -9.39007553e-02 -4.79871207e-02\n",
            "  2.69871217e-02  4.32454546e-02  8.34621280e-03 -4.71227274e-02\n",
            "  1.11727273e-01  3.30484841e-02 -1.94318183e-02 -3.49818182e-02\n",
            "  4.80295450e-02 -2.83098483e-02 -1.85045459e-02  3.59848488e-02\n",
            " -1.71628779e-02 -2.64446969e-02 -5.75151503e-03  7.22492403e-02\n",
            " -5.04318196e-03 -1.28171969e-01 -2.60765150e-02 -1.38750005e-02\n",
            " -8.42931821e-02 -5.55265157e-02  4.31492427e-02  1.51395453e-01\n",
            "  4.52098485e-02 -9.33537869e-02  4.26818194e-02  2.43075746e-02\n",
            "  6.92803108e-03 -2.93204540e-02  7.45772728e-02  5.68886354e-02\n",
            " -1.30621214e-02  1.94674235e-02  5.18636369e-02 -2.06196974e-02\n",
            " -8.90757573e-03  9.03863627e-03 -7.20340901e-02 -1.51439347e-03\n",
            "  2.22522730e-02  1.49712128e-02  3.63431829e-02  2.55363630e-02\n",
            "  8.10522721e-02  1.06242427e-02 -1.15295457e-02 -5.21969698e-02\n",
            " -5.72782579e-01 -1.07674244e-02 -9.15302977e-03 -2.52348481e-03\n",
            " -1.20272724e-02 -9.72287864e-02  4.81742337e-03 -6.21207538e-05\n",
            "  1.66803030e-02  3.73742420e-02 -1.69286366e-01  4.01537870e-02\n",
            " -1.75204541e-02 -3.24007579e-02  3.13757577e-02  4.10272718e-02\n",
            "  3.32356055e-02  5.70757575e-02  1.53303035e-02 -1.12871215e-02\n",
            "  1.27719695e-02  1.68884088e-01  2.41840905e-02 -7.15530280e-03\n",
            " -5.20984850e-02 -3.84151511e-02  5.18378788e-02 -8.92219697e-02\n",
            "  1.44143940e-02 -1.54545455e-02 -7.21515174e-03 -1.34200001e-01\n",
            "  2.52083335e-02  1.56848483e-02 -5.42712130e-02 -7.80303176e-04\n",
            "  3.50257591e-02 -3.85000001e-02  4.23325762e-02  2.75272723e-02\n",
            "  6.25621215e-02 -7.67568191e-02 -1.00606040e-03  5.33916673e-02\n",
            "  3.82931814e-02 -3.78462118e-02 -2.05704547e-02 -5.33484897e-03\n",
            " -1.60725758e-01  9.86060631e-03  6.79015100e-03 -1.37628782e-02\n",
            " -7.13462117e-02  2.64719705e-02  9.88635510e-04  2.30492424e-02\n",
            " -1.08765909e-01 -2.35560614e-02 -1.70530303e-02  1.75378761e-03\n",
            "  9.87371230e-02  3.49977288e-02 -2.61628791e-02  7.68189406e-02\n",
            "  7.90757464e-03 -7.99151525e-02 -6.55386371e-02 -2.81790150e-01\n",
            "  3.14954553e-02 -1.52446978e-02 -1.82060609e-02 -6.62590899e-02\n",
            " -2.73242430e-02  1.59707577e-01  3.57742424e-02  2.18938906e-04\n",
            " -3.85265153e-02  8.35757593e-03  1.75909094e-02  2.91075767e-02\n",
            "  3.96606057e-02  5.86446960e-02 -5.80765147e-02 -1.20392424e-01\n",
            " -1.52287878e-02 -1.14651509e-02 -4.83848485e-02  3.70772729e-02\n",
            " -8.75757609e-03 -7.44318131e-03  5.51765164e-02  2.16341665e-01\n",
            "  3.92037886e-02 -3.52878785e-02  7.23424248e-02  5.68401505e-02\n",
            "  1.26060613e-02 -1.32272732e-03  3.05833335e-02  5.99863629e-02\n",
            " -3.35053030e-02  2.08840909e-02 -1.08689401e-02  3.70356058e-02\n",
            "  7.52575726e-03  5.60454500e-03 -2.82984850e-02 -1.47742425e-02\n",
            " -1.44621163e-03 -2.64151514e-02  3.36856064e-02  1.84437121e-01\n",
            " -3.82484855e-02  3.13818179e-02  1.59388634e-01 -2.71318184e-02\n",
            " -2.99045456e-02 -5.60303009e-03  3.44530301e-02  5.17121217e-03\n",
            " -2.04507568e-02 -3.94848487e-03  2.63280306e-02  3.67878789e-03\n",
            "  1.95751515e-01 -8.64166641e-03 -1.67189403e-02 -3.14469688e-03\n",
            "  2.16075749e-02  5.18863633e-02 -2.57674238e-02 -5.54696952e-03\n",
            " -3.60424237e-02 -8.12068181e-02 -4.92992423e-02 -2.65598485e-02\n",
            "  1.30613639e-02  7.84295447e-02  5.78636361e-02  6.21378786e-02\n",
            " -2.65515152e-02 -1.53787956e-04 -2.41765150e-02 -2.51954545e-02\n",
            " -2.60780297e-02 -3.61333333e-02  5.81083330e-02 -1.50196971e-02\n",
            "  2.06333336e-02 -8.21931825e-02 -4.77553037e-02 -4.19696981e-03\n",
            " -1.03757573e-02  2.40704544e-02  8.77878787e-03  3.83151509e-02\n",
            "  3.28583331e-02 -2.92454546e-02 -7.60681844e-03 -1.70727286e-02\n",
            " -3.84621157e-03  2.17969694e-02  2.44469695e-02 -6.88863639e-02\n",
            "  9.53007569e-02 -2.81954555e-02 -9.11454556e-02  9.07401504e-02\n",
            " -8.40113627e-02 -3.14901507e-02 -6.19825758e-02 -4.42833321e-02\n",
            " -5.18295460e-02 -1.17688636e-01 -4.86871213e-02 -1.53909096e-02\n",
            "  6.34999973e-03 -9.14196977e-02  2.93666663e-02 -2.15568186e-02\n",
            "  2.93406064e-01 -1.14910607e-01 -6.33712068e-03 -3.31507578e-02\n",
            " -6.86136290e-03 -9.63924221e-02 -1.78437121e-01 -2.44484851e-02\n",
            "  3.14825744e-02 -1.27204536e-02  9.85606067e-03 -7.93333347e-03\n",
            " -5.21333336e-02  1.08520455e-01  5.19189392e-02 -2.16712123e-02\n",
            "  5.06333317e-02  2.49111363e-01  4.17159091e-02 -3.12068184e-02\n",
            "  1.09669697e-01  8.79242400e-03  7.31901518e-02 -2.66212075e-03\n",
            " -2.17484839e-02 -3.06371211e-02 -9.19772690e-03  1.32174240e-02\n",
            " -2.40606057e-03 -2.04765146e-02  6.12954521e-03  2.76454550e-02\n",
            " -2.65787878e-01  5.57628800e-02  5.09825768e-02 -2.09227274e-02\n",
            "  2.84590919e-02 -1.89492431e-02 -1.70840911e-02  2.63840913e-02\n",
            "  1.69113636e-02  4.79757567e-02 -3.02053021e-02 -2.80530286e-03\n",
            " -8.54068190e-02 -8.69242425e-02  4.74007573e-02  3.36265152e-02\n",
            " -1.36439381e-03  7.30037875e-02  6.04545470e-03 -3.07446973e-02\n",
            "  1.64492426e-02 -2.76750009e-02  1.26244697e-01 -8.10303096e-03\n",
            "  1.30507572e-02  3.58803033e-02  2.33098478e-02  8.46212082e-03\n",
            " -4.06893905e-03  4.71166665e-02  1.69628785e-02  2.39719701e-02\n",
            "  7.78106008e-03 -2.37810609e-02 -2.90537872e-02  1.25719698e-02]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# FastText embedding for NepalEQ_df\n",
        "NepalEQ_df_embeddings_fasttext = get_embeddings(fasttext_model, NepalEQ_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(NepalEQ_df_embeddings_fasttext), len(NepalEQ_df_embeddings_fasttext[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % NepalEQ_df['joined_words'][0])\n",
        "print(NepalEQ_df_embeddings_fasttext[0])"
      ],
      "id": "3Hj87cXozouz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4neFokjCz7_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3f3613-bcb6-48bd-cbea-e0436d1709f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix size 6019 300\n",
            "The sentence: \"i just though about the night i went clubbing with mikal and i cried\" got embedding values: \n",
            "[-9.66705884e-02  2.84058822e-02 -6.99882343e-02 -3.63455885e-02\n",
            "  3.88132357e-02  3.05161761e-02  2.02455889e-02 -1.55852946e-02\n",
            "  1.28619119e-01  3.68249993e-02 -1.20161768e-02 -3.81323521e-02\n",
            "  3.56088231e-02 -3.37058827e-02 -4.81750011e-02  3.66794122e-02\n",
            " -1.85617644e-02 -2.64264704e-02 -2.05367648e-02  5.61985281e-02\n",
            " -3.16911706e-03 -1.14554412e-01 -3.04691177e-02 -7.48529448e-04\n",
            " -7.21117642e-02 -6.65485294e-02  3.12132355e-02  1.75638233e-01\n",
            "  6.18338245e-02 -9.11897057e-02  6.80058822e-02 -2.42205959e-03\n",
            "  3.24220597e-02  1.88235014e-04  8.48794116e-02  4.20941176e-02\n",
            " -1.24676471e-02  5.02705869e-02  5.82985304e-02 -4.36176513e-03\n",
            " -9.03529401e-03  2.07661762e-02 -6.42897053e-02  1.45029413e-02\n",
            "  1.02573528e-02  3.02352954e-02 -2.11838234e-02  5.55220580e-02\n",
            "  9.61955886e-02 -1.26323518e-03 -2.30691176e-02 -4.45279410e-02\n",
            " -5.61247057e-01 -2.62544127e-02 -1.26823526e-02  1.52029408e-02\n",
            "  6.53676436e-03 -1.11242645e-01  3.32352541e-04  8.62352957e-03\n",
            "  3.80000023e-03  1.28029408e-02 -1.33744119e-01  4.72499989e-02\n",
            " -2.82161762e-02 -7.18308826e-02  3.01676471e-02  4.13044109e-02\n",
            "  2.06191174e-02  4.68735290e-02  1.16470595e-02 -1.32411767e-02\n",
            "  1.89985292e-02  1.77088233e-01  2.75308815e-02  1.63823588e-03\n",
            " -5.65029412e-02 -3.65838238e-02  3.55764711e-02 -5.08220593e-02\n",
            "  9.03676453e-03 -1.25970591e-02 -1.49441176e-02 -1.31472060e-01\n",
            "  2.22999998e-02  1.49529413e-02 -6.53397067e-02  1.54264645e-03\n",
            " -6.76911675e-03 -3.15161767e-02  5.21161768e-02  8.71029437e-03\n",
            "  3.52720585e-02 -7.79500011e-02  9.35735279e-03  2.59176472e-02\n",
            "  2.48661767e-02 -2.89073520e-02 -1.78058828e-02 -2.86588244e-02\n",
            " -1.66855883e-01  5.38529471e-03  9.74264686e-03 -1.98558820e-02\n",
            " -5.69720590e-02  3.40823531e-02 -4.98823628e-03  1.18955887e-02\n",
            " -9.66279407e-02 -2.86911778e-03 -1.68852946e-02  1.21029396e-03\n",
            "  1.00630884e-01  3.68779430e-02 -5.85779413e-02  7.39220605e-02\n",
            " -1.11441185e-02 -5.91720595e-02 -9.08264716e-02 -2.89919116e-01\n",
            "  1.84544121e-02  1.78455877e-02 -2.88661776e-02 -6.78544115e-02\n",
            " -3.79941186e-02  1.34072059e-01  4.18558824e-02  1.58808821e-02\n",
            " -4.23617652e-02 -3.38529454e-03 -3.69705839e-03  8.86323580e-03\n",
            "  3.63588233e-02  3.69279402e-02 -6.24397057e-02 -1.19802939e-01\n",
            " -1.20044119e-02 -2.70102945e-02 -2.45455887e-02  3.37161761e-02\n",
            "  1.60529406e-02  6.66323570e-03  1.21058840e-02  1.90033821e-01\n",
            "  2.08073535e-02 -6.34911763e-02  7.43191194e-02  7.72779413e-02\n",
            "  3.50867658e-02 -7.48382328e-03  2.94147057e-02  7.76573522e-02\n",
            " -1.08602942e-02  1.13985294e-02 -2.70705893e-02  5.57514707e-02\n",
            " -1.58808825e-02 -6.25294151e-03 -3.26411768e-02 -2.42750004e-02\n",
            "  1.24794121e-02 -2.57294113e-02  3.25544121e-02  1.76998527e-01\n",
            " -5.80382361e-02  6.33455877e-02  1.56519117e-01 -4.35485296e-02\n",
            " -1.65485295e-02 -2.90588244e-03  1.24852941e-02 -3.95882353e-03\n",
            " -3.64279405e-02 -3.91176452e-03  3.17308825e-02  2.68955879e-02\n",
            "  1.97602942e-01  8.18397055e-02  1.28867642e-02 -2.45397055e-02\n",
            "  8.31176446e-03  4.83308821e-02 -2.62147055e-02  8.02500025e-03\n",
            " -3.13205878e-02 -1.09495588e-01 -4.80911757e-02 -2.30161764e-02\n",
            " -2.90102939e-02  7.14735300e-02  4.33661762e-02  6.07838237e-02\n",
            " -4.50441178e-02 -6.51176510e-03 -2.25852940e-02 -6.09000005e-02\n",
            " -3.97279404e-02 -4.31132354e-02  4.77529412e-02 -1.87058822e-02\n",
            "  5.24426470e-02 -6.85897061e-02 -2.25941180e-02  1.35485294e-02\n",
            " -1.46735290e-02  2.08235295e-02  3.37058784e-03  4.23264698e-02\n",
            "  3.57176470e-02 -3.63632355e-02  1.41911714e-03 -2.09735304e-02\n",
            "  8.69117711e-03  2.70588218e-03  3.36367647e-02 -6.51588234e-02\n",
            "  5.62029397e-02 -2.22264713e-02 -6.82500015e-02  9.87617630e-02\n",
            " -1.10952940e-01 -3.91411755e-02 -4.91117652e-02 -1.13426466e-02\n",
            " -4.30941187e-02 -1.21707352e-01 -5.25632350e-02  1.01852940e-02\n",
            "  1.32338232e-02 -7.66279407e-02  5.06191168e-02 -1.14176477e-02\n",
            "  2.81572063e-01 -1.24913236e-01 -2.44705850e-03  1.65147052e-03\n",
            " -7.48382349e-03 -8.99441158e-02 -1.51994118e-01 -9.94852959e-03\n",
            "  4.31058809e-02 -1.95897060e-02 -3.83382356e-03 -2.96882354e-02\n",
            " -5.93941179e-02  9.85735309e-02  5.00352937e-02 -1.65338236e-02\n",
            "  6.27911757e-02  1.86289704e-01  3.29808826e-02 -2.52191180e-02\n",
            "  1.29947058e-01  1.52735292e-02  7.30147062e-02  3.32058849e-03\n",
            " -3.70852933e-02 -2.60294116e-02 -1.03617637e-02 -5.10441180e-03\n",
            "  2.01705886e-02 -2.10426467e-02 -7.57058845e-03  1.02250004e-02\n",
            " -2.72748529e-01  4.17705886e-02  3.71882359e-02 -3.09661768e-02\n",
            "  4.15441183e-02 -4.34176482e-02 -2.01808824e-02  3.63411769e-02\n",
            "  1.76808828e-02  5.19279410e-02 -2.06852937e-02  2.53632355e-02\n",
            " -6.82529425e-02 -9.76220586e-02  3.90367646e-02  4.22426467e-02\n",
            "  1.44838242e-02  8.91117644e-02 -2.41029414e-03 -2.10544120e-02\n",
            "  2.26544119e-02 -4.96970601e-02  1.09720588e-01  3.85293545e-04\n",
            "  1.23000003e-02  3.13044119e-02 -9.20588702e-04  2.46397056e-02\n",
            " -3.39705875e-03  5.61058828e-02  4.55985298e-02  2.25705883e-02\n",
            "  1.61147053e-02 -1.58573526e-02 -2.47029407e-02  8.09117672e-03]\n"
          ]
        }
      ],
      "source": [
        "# FastText embedding for QueenslandFLD_df\n",
        "QueenslandFLD_df_embeddings_fasttext = get_embeddings(fasttext_model, QueenslandFLD_df['joined_words'], k=300)\n",
        "\n",
        "print(\"Embedding matrix size\", len(QueenslandFLD_df_embeddings_fasttext), len(QueenslandFLD_df_embeddings_fasttext[0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % QueenslandFLD_df['joined_words'][0])\n",
        "print(QueenslandFLD_df_embeddings_fasttext[0])"
      ],
      "id": "4neFokjCz7_I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q_Dj-amy6il"
      },
      "source": [
        "### BERT"
      ],
      "id": "2Q_Dj-amy6il"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKDM63_J_2yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c08b78-2b4e-4350-99a2-e68c635eca56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# download the tonkenizer \n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "#!pip3 install tokenization\n",
        "#import tokenization\n",
        "#!pip install bert-tensorflow\n",
        "#from bert import tokenization\n",
        "#from bert import bert_tokenization\n",
        "!pip install --upgrade transformers\n",
        "from transformers import BertTokenizer"
      ],
      "id": "PKDM63_J_2yj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hET69vf1Cujq"
      },
      "outputs": [],
      "source": [
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "id": "hET69vf1Cujq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuI3mdqk_5L4"
      },
      "outputs": [],
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "id": "UuI3mdqk_5L4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y6Ail6lBEBu"
      },
      "outputs": [],
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "#tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "tokenizer = BertTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "# BERT for NepalEQ_df\n",
        "NepalEQ_df_bert_input = bert_encode(NepalEQ_df['joined_words'].values, tokenizer, max_len=200)\n",
        "\n",
        "# BERT for QueenslandFLD_df\n",
        "QueenslandFLD_df_bert_input = bert_encode(QueenslandFLD_df['joined_words'].values, tokenizer, max_len=200)"
      ],
      "id": "7y6Ail6lBEBu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4g86YHpCak4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7b1564-5a8d-4524-d1c2-62adae911fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding tensor size 3 6899 200\n",
            "[[  101 19387  2019 ...     0     0     0]\n",
            " [  101  6285  2015 ...     0     0     0]\n",
            " [  101 18496  1037 ...     0     0     0]\n",
            " ...\n",
            " [  101 11968 26095 ...     0     0     0]\n",
            " [  101  3892  2006 ...     0     0     0]\n",
            " [  101 10905  7630 ...     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Embedding tensor size\", len(NepalEQ_df_bert_input), len(NepalEQ_df_bert_input[0]), len(NepalEQ_df_bert_input[0][0]))\n",
        "#print(\"The sentence: \\\"%s\\\" got embedding values: \" % NepalEQ_df_bert_input['joined_words'][0])\n",
        "print(NepalEQ_df_bert_input[0])"
      ],
      "id": "H4g86YHpCak4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsEXz2NJTUfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bb2998-1d0c-4855-cad3-19006a7d347a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding tensor size 3 6019 200\n",
            "The sentence: \"i just though about the night i went clubbing with mikal and i cried\" got embedding values: \n",
            "[[  101  1045  2074 ...     0     0     0]\n",
            " [  101  2298  2066 ...     0     0     0]\n",
            " [  101 17595  6137 ...     0     0     0]\n",
            " ...\n",
            " [  101 19387  2739 ...     0     0     0]\n",
            " [  101 19387  5925 ...     0     0     0]\n",
            " [  101 19387  2188 ...     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Embedding tensor size\", len(QueenslandFLD_df_bert_input), len(QueenslandFLD_df_bert_input[0]), len(QueenslandFLD_df_bert_input[0][0]))\n",
        "print(\"The sentence: \\\"%s\\\" got embedding values: \" % QueenslandFLD_df['joined_words'][0])\n",
        "print(QueenslandFLD_df_bert_input[0])"
      ],
      "id": "LsEXz2NJTUfT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEMvlMmoYIbI"
      },
      "source": [
        "## Classification "
      ],
      "id": "TEMvlMmoYIbI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI2hXxRXXQqX"
      },
      "outputs": [],
      "source": [
        "# Replace the label column with 1's and 0's using pandas.replace\n",
        "# NepalEQ_df['label'] = NepalEQ_df['label'].replace({'relevant': 1, 'not_relevant': 0})\n",
        "# QueenslandFLD_df['label'] = QueenslandFLD_df['label'].replace({'relevant': 1, 'not_relevant': 0})\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assume your label column is called 'class_label'\n",
        "label_encoder = LabelEncoder()\n",
        "NepalEQ_df['label'] = label_encoder.fit_transform(NepalEQ_df['label'])\n",
        "QueenslandFLD_df['label'] = label_encoder.fit_transform(QueenslandFLD_df['label'])\n",
        "\n",
        "np.save('NepalEQ_df_label.npy', NepalEQ_df.label)\n",
        "np.save('QueenslandFLD_df_label.npy', QueenslandFLD_df.label)"
      ],
      "id": "pI2hXxRXXQqX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1_SnHdZBDVB"
      },
      "source": [
        "### Concatenate all vectors"
      ],
      "id": "i1_SnHdZBDVB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABpMHdruP4v5",
        "outputId": "d1ecf131-3272-44f4-9cee-1e36467b25b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label', 'tokens', 'lemmatize_word', 'combined_postag_wnet',\n",
              "       'joined_words', 'Noun_Count', 'Verb_Count', 'Adjective_Count',\n",
              "       'Adverb_Count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "NepalEQ_df.columns"
      ],
      "id": "ABpMHdruP4v5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "020MYCmi9xiA"
      },
      "source": [
        "#### Hashtags"
      ],
      "id": "020MYCmi9xiA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIwxQAjg_uJ-"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a 2D array\n",
        "NepalEQ_hashtag_arr = NepalEQ_hashtag_df.to_numpy()\n",
        "NepalEQ_hashtag_arr_matrix = coo_matrix(NepalEQ_hashtag_arr).toarray()\n",
        "\n",
        "# Convert the dataframe to a 2D array\n",
        "QueenslandFLD_hashtag_arr = QueenslandFLD_hashtag_df.to_numpy()\n",
        "QueenslandFLD_hashtag_arr_matrix = coo_matrix(QueenslandFLD_hashtag_arr).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_hashtag_arr_matrix.npy', NepalEQ_hashtag_arr_matrix)\n",
        "np.save('QueenslandFLD_hashtag_arr_matrix.npy', QueenslandFLD_hashtag_arr_matrix)"
      ],
      "id": "ZIwxQAjg_uJ-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFYVOJcE9xpg"
      },
      "source": [
        "#### Retweets"
      ],
      "id": "UFYVOJcE9xpg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6h6gKqQAPMy"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a 2D array\n",
        "NepalEQ_retweet_arr = NepalEQ_retweet_df.to_numpy()\n",
        "NepalEQ_retweet_arr_matrix = coo_matrix(NepalEQ_retweet_arr).toarray()\n",
        "\n",
        "# Convert the dataframe to a 2D array\n",
        "QueenslandFLD_retweet_arr = QueenslandFLD_retweet_df.to_numpy()\n",
        "QueenslandFLD_retweet_arr_matrix = coo_matrix(QueenslandFLD_retweet_arr).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_retweet_arr_matrix.npy', NepalEQ_retweet_arr_matrix)\n",
        "np.save('QueenslandFLD_retweet_arr_matrix.npy', QueenslandFLD_retweet_arr_matrix)"
      ],
      "id": "O6h6gKqQAPMy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYAzeBE9xwR"
      },
      "source": [
        "#### BOW"
      ],
      "id": "RGYAzeBE9xwR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVkwe4BuAQA3"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a 2D array\n",
        "NepalEQ_df_em_1gram_matrix = coo_matrix(NepalEQ_df_em_1gram).toarray()\n",
        "\n",
        "# Convert the dataframe to a 2D array\n",
        "QueenslandFLD_df_em_1gram_matrix = coo_matrix(QueenslandFLD_df_em_1gram).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_em_1gram_matrix.npy', NepalEQ_df_em_1gram_matrix)\n",
        "np.save('QueenslandFLD_df_em_1gram_matrix.npy', QueenslandFLD_df_em_1gram_matrix)"
      ],
      "id": "YVkwe4BuAQA3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_36hPzy9x4W"
      },
      "source": [
        "#### POS"
      ],
      "id": "C_36hPzy9x4W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxqaULGHAQqz"
      },
      "outputs": [],
      "source": [
        "# Convert the new DataFrame to a NumPy array for NepalEQ_df\n",
        "NepalEQ_POS_selected = NepalEQ_df[['Noun_Count', 'Verb_Count', 'Adjective_Count', 'Adverb_Count']]\n",
        "# Convert the dataframe to a 2D array\n",
        "NepalEQ_POS_arr = NepalEQ_POS_selected.to_numpy()\n",
        "NepalEQ_POS_matrix = coo_matrix(NepalEQ_POS_arr).toarray()\n",
        "\n",
        "# Convert the new DataFrame to a NumPy array for QueenslandFLD_df\n",
        "QueenslandFLD_POS_selected = QueenslandFLD_df[['Noun_Count', 'Verb_Count', 'Adjective_Count', 'Adverb_Count']]\n",
        "# Convert the dataframe to a 2D array\n",
        "QueenslandFLD_df_POS_arr = QueenslandFLD_POS_selected.to_numpy()\n",
        "QueenslandFLD_POS_matrix = coo_matrix(QueenslandFLD_df_POS_arr).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_POS_matrix.npy', NepalEQ_POS_matrix)\n",
        "np.save('QueenslandFLD_POS_matrix.npy', QueenslandFLD_POS_matrix)"
      ],
      "id": "GxqaULGHAQqz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTzW9aTA9x_5"
      },
      "source": [
        "#### Fasttext"
      ],
      "id": "vTzW9aTA9x_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddq3tATpARL3"
      },
      "outputs": [],
      "source": [
        "# Create a sparse matrix in COO format NepalEQ_df_embeddings_fasttext\n",
        "NepalEQ_df_embeddings_fasttext_matrix = coo_matrix(NepalEQ_df_embeddings_fasttext).toarray()\n",
        "\n",
        "# Create a sparse matrix in COO format QueenslandFLD_df_embeddings_fasttext\n",
        "QueenslandFLD_df_embeddings_fasttext_matrix = coo_matrix(QueenslandFLD_df_embeddings_fasttext).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_embeddings_fasttext_matrix.npy', NepalEQ_df_embeddings_fasttext_matrix)\n",
        "np.save('QueenslandFLD_df_embeddings_fasttext_matrix.npy', QueenslandFLD_df_embeddings_fasttext_matrix)"
      ],
      "id": "ddq3tATpARL3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKIEBG2a9yIf"
      },
      "source": [
        "#### Word2Vec"
      ],
      "id": "WKIEBG2a9yIf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJR8Pz3TAR6w"
      },
      "outputs": [],
      "source": [
        "# Create a sparse matrix in COO format NepalEQ_df_embeddings_word2vec\n",
        "NepalEQ_df_embeddings_word2vec_matrix = coo_matrix(NepalEQ_df_embeddings_word2vec).toarray()\n",
        "\n",
        "# Create a sparse matrix in COO format QueenslandFLD_df_embeddings_word2vec\n",
        "QueenslandFLD_df_embeddings_word2vec_matrix = coo_matrix(QueenslandFLD_df_embeddings_word2vec).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_embeddings_word2vec_matrix.npy', NepalEQ_df_embeddings_word2vec_matrix)\n",
        "np.save('QueenslandFLD_df_embeddings_word2vec_matrix.npy', QueenslandFLD_df_embeddings_word2vec_matrix)"
      ],
      "id": "VJR8Pz3TAR6w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwpFMnlM9yQD"
      },
      "source": [
        "#### Glove"
      ],
      "id": "AwpFMnlM9yQD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NIqd_HMATGQ"
      },
      "outputs": [],
      "source": [
        "# Create a sparse matrix in COO format NepalEQ_df_embeddings_glove\n",
        "NepalEQ_df_embeddings_glove_matrix = coo_matrix(NepalEQ_df_embeddings_glove[0]).toarray()\n",
        "\n",
        "# Create a sparse matrix in COO format QueenslandFLD_df_embeddings_glove\n",
        "QueenslandFLD_df_embeddings_glove_matrix = coo_matrix(QueenslandFLD_df_embeddings_glove[0]).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_embeddings_glove_matrix.npy', NepalEQ_df_embeddings_glove_matrix)\n",
        "np.save('QueenslandFLD_df_embeddings_glove_matrix.npy', QueenslandFLD_df_embeddings_glove_matrix)"
      ],
      "id": "0NIqd_HMATGQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Y4MegX9yXV"
      },
      "source": [
        "#### Bert"
      ],
      "id": "Y3Y4MegX9yXV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZTP7nNsAUoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "19711be9-dfb8-4695-84d5-5a60e529f206"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-f31f44281ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a sparse matrix in COO format NepalEQ_df_bert_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNepalEQ_df_bert_input_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNepalEQ_df_bert_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a sparse matrix in COO format QueenslandFLD_df_embeddings_glove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mQueenslandFLD_df_bert_input_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueenslandFLD_df_bert_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid input format'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: invalid input format"
          ]
        }
      ],
      "source": [
        "# Create a sparse matrix in COO format NepalEQ_df_bert_input\n",
        "NepalEQ_df_bert_input_matrix = coo_matrix(NepalEQ_df_bert_input).toarray()\n",
        "\n",
        "# Create a sparse matrix in COO format QueenslandFLD_df_embeddings_glove\n",
        "QueenslandFLD_df_bert_input_matrix = coo_matrix(QueenslandFLD_df_bert_input).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_bert_input_matrix.npy', NepalEQ_df_bert_input_matrix)\n",
        "np.save('QueenslandFLD_df_bert_input_matrix.npy', QueenslandFLD_df_bert_input_matrix)"
      ],
      "id": "2ZTP7nNsAUoc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Qnel6gOkv_"
      },
      "source": [
        "#### TF-IDF"
      ],
      "id": "I7Qnel6gOkv_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i0VNvReOq-d"
      },
      "outputs": [],
      "source": [
        "# Convert the dataframe to a 2D array\n",
        "NepalEQ_df_tfidf_1gram_matrix = coo_matrix(NepalEQ_df_tfidf_1gram).toarray()\n",
        "\n",
        "# Convert the dataframe to a 2D array\n",
        "QueenslandFLD_df_tfidf_1gram_matrix = coo_matrix(QueenslandFLD_df_tfidf_1gram).toarray()\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_df_tfidf_1gram_matrix.npy', NepalEQ_df_tfidf_1gram_matrix)\n",
        "np.save('QueenslandFLD_df_tfidf_1gram_matrix.npy', QueenslandFLD_df_tfidf_1gram_matrix)"
      ],
      "id": "6i0VNvReOq-d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Geovq-91Ie"
      },
      "source": [
        "#### TF-IDF + hashtags + Retweets + POS + FT"
      ],
      "id": "o9Geovq-91Ie"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329Qvt6kOdqZ"
      },
      "outputs": [],
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_retweet_arr_matrix2 = coo_matrix(NepalEQ_retweet_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_embeddings_fasttext_matrix2 = coo_matrix(NepalEQ_df_embeddings_fasttext)\n",
        "NepalEQ_TFIDF_HT_RT_POS_FT_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                    NepalEQ_hashtag_arr_matrix2, \n",
        "                                    NepalEQ_retweet_arr_matrix2, \n",
        "                                    NepalEQ_POS_matrix2, \n",
        "                                    NepalEQ_df_embeddings_fasttext_matrix2]).toarray()\n",
        "\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_retweet_arr_matrix2 = coo_matrix(QueenslandFLD_retweet_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_embeddings_fasttext_matrix2 = coo_matrix(QueenslandFLD_df_embeddings_fasttext)\n",
        "QueenslandFLD_TFIDF_HT_RT_POS_FT_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                    QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                    QueenslandFLD_retweet_arr_matrix2, \n",
        "                                    QueenslandFLD_POS_matrix2, \n",
        "                                    QueenslandFLD_df_embeddings_fasttext_matrix2]).toarray()\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_RT_POS_FT_hstack.npy', NepalEQ_TFIDF_HT_RT_POS_FT_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_RT_POS_FT_hstack.npy', QueenslandFLD_TFIDF_HT_RT_POS_FT_hstack)                                    "
      ],
      "id": "329Qvt6kOdqZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoUWb_CBX1j1"
      },
      "outputs": [],
      "source": [
        "QueenslandFLD_hashtag_arr_matrix2.shape"
      ],
      "id": "QoUWb_CBX1j1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQiHLneS-rWT"
      },
      "source": [
        "#### TF-IDF + hashtags + Retweets + POS + word2vec"
      ],
      "id": "oQiHLneS-rWT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqj4vwpiRHIM"
      },
      "outputs": [],
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_retweet_arr_matrix2 = coo_matrix(NepalEQ_retweet_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_embeddings_word2vec_matrix2 = coo_matrix(NepalEQ_df_embeddings_word2vec)\n",
        "NepalEQ_TFIDF_HT_RT_POS_w2v_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                              NepalEQ_hashtag_arr_matrix2, \n",
        "                                              NepalEQ_retweet_arr_matrix2, \n",
        "                                              NepalEQ_POS_matrix2, \n",
        "                                              NepalEQ_df_embeddings_word2vec_matrix2]).toarray()\n",
        "\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_retweet_arr_matrix2 = coo_matrix(QueenslandFLD_retweet_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_embeddings_word2vec_matrix2 = coo_matrix(QueenslandFLD_df_embeddings_word2vec)\n",
        "QueenslandFLD_TFIDF_HT_RT_POS_w2v_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                                    QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                                    QueenslandFLD_retweet_arr_matrix2, \n",
        "                                                    QueenslandFLD_POS_matrix2, \n",
        "                                                    QueenslandFLD_df_embeddings_word2vec_matrix2]).toarray()\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_RT_POS_w2v_hstack.npy', NepalEQ_TFIDF_HT_RT_POS_w2v_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_RT_POS_w2v_hstack.npy', QueenslandFLD_TFIDF_HT_RT_POS_w2v_hstack)                                                     "
      ],
      "id": "Zqj4vwpiRHIM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si-WBSGP-rbd"
      },
      "source": [
        "#### TF-IDF + hashtags + Retweets + POS + Glove"
      ],
      "id": "si-WBSGP-rbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8cDt3K8RnTC"
      },
      "outputs": [],
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_retweet_arr_matrix2 = coo_matrix(NepalEQ_retweet_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_embeddings_glove_matrix2 = coo_matrix(NepalEQ_df_embeddings_glove)\n",
        "NepalEQ_TFIDF_HT_RT_POS_glove_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                     NepalEQ_hashtag_arr_matrix2, \n",
        "                                     NepalEQ_retweet_arr_matrix2, \n",
        "                                     NepalEQ_POS_matrix2, \n",
        "                                     NepalEQ_df_embeddings_glove_matrix2]).toarray()\n",
        "\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_retweet_arr_matrix2 = coo_matrix(QueenslandFLD_retweet_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_embeddings_glove_matrix2 = coo_matrix(QueenslandFLD_df_embeddings_glove)\n",
        "QueenslandFLD_TFIDF_HT_RT_POS_glove_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                     QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                     QueenslandFLD_retweet_arr_matrix2, \n",
        "                                     QueenslandFLD_POS_matrix2, \n",
        "                                     QueenslandFLD_df_embeddings_glove_matrix2]).toarray()\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_RT_POS_glove_hstack.npy', NepalEQ_TFIDF_HT_RT_POS_glove_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_RT_POS_glove_hstack.npy', QueenslandFLD_TFIDF_HT_RT_POS_glove_hstack)                                     "
      ],
      "id": "H8cDt3K8RnTC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSbyzGr-rga"
      },
      "source": [
        "#### TF-IDF + hashtags + Retweets + POS + bert"
      ],
      "id": "tQSbyzGr-rga"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XtFEfKoRsG1"
      },
      "outputs": [],
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_retweet_arr_matrix2 = coo_matrix(NepalEQ_retweet_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_bert_input_matrix2 = coo_matrix(NepalEQ_df_bert_input[0])\n",
        "NepalEQ_TFIDF_HT_RT_POS_bert_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                     NepalEQ_hashtag_arr_matrix2, \n",
        "                                     NepalEQ_retweet_arr_matrix2, \n",
        "                                     NepalEQ_POS_matrix2, \n",
        "                                     NepalEQ_df_bert_input_matrix2]).toarray()\n",
        "\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_retweet_arr_matrix2 = coo_matrix(QueenslandFLD_retweet_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_bert_input_matrix2 = coo_matrix(QueenslandFLD_df_bert_input[0])\n",
        "QueenslandFLD_TFIDF_HT_RT_POS_bert_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                     QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                     QueenslandFLD_retweet_arr_matrix2, \n",
        "                                     QueenslandFLD_POS_matrix2, \n",
        "                                     QueenslandFLD_df_bert_input_matrix2]).toarray()\n",
        "\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_RT_POS_bert_hstack.npy', NepalEQ_TFIDF_HT_RT_POS_bert_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_RT_POS_bert_hstack.npy', QueenslandFLD_TFIDF_HT_RT_POS_bert_hstack)                                    "
      ],
      "id": "8XtFEfKoRsG1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### hastags + POS + TF-IDF"
      ],
      "metadata": {
        "id": "dVtWxagHodap"
      },
      "id": "dVtWxagHodap"
    },
    {
      "cell_type": "code",
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_TFIDF_HT_POS_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                     NepalEQ_hashtag_arr_matrix2,  \n",
        "                                     NepalEQ_POS_matrix2]).toarray()\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_TFIDF_HT_POS_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                            QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                            QueenslandFLD_POS_matrix2]).toarray()\n",
        "\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_POS_hstack.npy', NepalEQ_TFIDF_HT_POS_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_POS_hstack.npy', QueenslandFLD_TFIDF_HT_POS_hstack)                                    "
      ],
      "metadata": {
        "id": "cKiRj6N7oo9_"
      },
      "id": "cKiRj6N7oo9_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### hastags + POS + TF-IDF + BERT"
      ],
      "metadata": {
        "id": "CxpCBtMch7us"
      },
      "id": "CxpCBtMch7us"
    },
    {
      "cell_type": "code",
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_bert_input_matrix2 = coo_matrix(NepalEQ_df_bert_input[0])\n",
        "NepalEQ_TFIDF_HT_POS_BERT_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                           NepalEQ_hashtag_arr_matrix2, \n",
        "                                           NepalEQ_POS_matrix2, \n",
        "                                           NepalEQ_df_bert_input_matrix2]).toarray()\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_bert_input_matrix2 = coo_matrix(QueenslandFLD_df_bert_input[0])\n",
        "QueenslandFLD_TFIDF_HT_POS_BERT_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                                 QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                                 QueenslandFLD_POS_matrix2, \n",
        "                                                 QueenslandFLD_df_bert_input_matrix2]).toarray()\n",
        "\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_POS_BERT_hstack.npy', NepalEQ_TFIDF_HT_POS_BERT_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_POS_BERT_hstack.npy', QueenslandFLD_TFIDF_HT_POS_BERT_hstack)     "
      ],
      "metadata": {
        "id": "15h42NtMgfqi"
      },
      "id": "15h42NtMgfqi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### hastags + POS + TF-IDF + GLoVe"
      ],
      "metadata": {
        "id": "XSFV2yvDFz76"
      },
      "id": "XSFV2yvDFz76"
    },
    {
      "cell_type": "code",
      "source": [
        "NepalEQ_df_tfidf_1gram_matrix2 = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "NepalEQ_hashtag_arr_matrix2 = coo_matrix(NepalEQ_hashtag_arr)\n",
        "NepalEQ_POS_matrix2 = coo_matrix(NepalEQ_POS_arr)\n",
        "NepalEQ_df_embeddings_glove_matrix2 = coo_matrix(NepalEQ_df_embeddings_glove)\n",
        "NepalEQ_TFIDF_HT_POS_GLOVE_hstack = hstack([NepalEQ_df_tfidf_1gram_matrix2, \n",
        "                                           NepalEQ_hashtag_arr_matrix2, \n",
        "                                           NepalEQ_POS_matrix2, \n",
        "                                           NepalEQ_df_embeddings_glove_matrix2]).toarray()\n",
        "\n",
        "QueenslandFLD_df_tfidf_1gram_matrix2 = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "QueenslandFLD_hashtag_arr_matrix2 = coo_matrix(QueenslandFLD_hashtag_arr)\n",
        "QueenslandFLD_POS_matrix2 = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "QueenslandFLD_df_embeddings_glove_matrix2 = coo_matrix(QueenslandFLD_df_embeddings_glove)\n",
        "QueenslandFLD_TFIDF_HT_POS_GLOVE_hstack = hstack([QueenslandFLD_df_tfidf_1gram_matrix2, \n",
        "                                                 QueenslandFLD_hashtag_arr_matrix2, \n",
        "                                                 QueenslandFLD_POS_matrix2, \n",
        "                                                 QueenslandFLD_df_embeddings_glove_matrix2]).toarray()\n",
        "\n",
        "\n",
        "\n",
        "# save to npy files\n",
        "np.save('NepalEQ_TFIDF_HT_POS_GLOVE_hstack.npy', NepalEQ_TFIDF_HT_POS_GLOVE_hstack)\n",
        "np.save('QueenslandFLD_TFIDF_HT_POS_GLOVE_hstack.npy', QueenslandFLD_TFIDF_HT_POS_GLOVE_hstack)  "
      ],
      "metadata": {
        "id": "x8i_rIEjFxux"
      },
      "id": "x8i_rIEjFxux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEahHXj426oB"
      },
      "id": "bEahHXj426oB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26WxBsWRUhdL"
      },
      "source": [
        "#### TF-IDF + hashtags + Retweets"
      ],
      "id": "26WxBsWRUhdL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY0tqcFO4O5C"
      },
      "outputs": [],
      "source": [
        "# # Convert the new DataFrame to a NumPy array for NepalEQ_df\n",
        "# NepalEQ_df_selected = NepalEQ_df[['hashtags_normalized','retweets_normalized']]\n",
        "# # Convert the dataframe to a 2D array\n",
        "# NepalEQ_arr = NepalEQ_df_selected.to_numpy()\n",
        "\n",
        "# # Create a sparse matrix in COO format\n",
        "# NepalEQ_arr_matrix = coo_matrix(NepalEQ_arr)\n",
        "# NepalEQ_df_tfidf_1gram_matrix = coo_matrix(NepalEQ_df_tfidf_1gram)\n",
        "# NepalEQ_df_tfidf_1gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_tfidf_1gram_matrix]).toarray()\n",
        "\n",
        "# # NepalEQ_arr_matrix = coo_matrix(NepalEQ_arr)\n",
        "# # NepalEQ_df_tfidf_2gram_matrix = coo_matrix(NepalEQ_df_tfidf_2gram)\n",
        "# # NepalEQ_df_tfidf_2gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_tfidf_2gram_matrix]).toarray()\n",
        "\n",
        "# # NepalEQ_arr_matrix = coo_matrix(NepalEQ_arr)\n",
        "# # NepalEQ_df_tfidf_3gram_matrix = coo_matrix(NepalEQ_df_tfidf_3gram)\n",
        "# # NepalEQ_df_tfidf_3gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_tfidf_3gram_matrix]).toarray()\n",
        "\n",
        "\n",
        "# # Convert the new DataFrame to a NumPy array for QueenslandFLD_df\n",
        "# QueenslandFLD_df_selected = QueenslandFLD_df[['hashtags', 'retweets']]\n",
        "# # Convert the dataframe to a 2D array\n",
        "# QueenslandFLD_arr = QueenslandFLD_df_selected.to_numpy()\n",
        "\n",
        "# # Create a sparse matrix in COO format\n",
        "# QueenslandFLD_arr_matrix = coo_matrix(QueenslandFLD_arr)\n",
        "# QueenslandFLD_df_tfidf_1gram_matrix = coo_matrix(QueenslandFLD_df_tfidf_1gram)\n",
        "# QueenslandFLD_df_tfidf_1gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_tfidf_1gram_matrix]).toarray()\n",
        "\n",
        "# # QueenslandFLD_arr_matrix = coo_matrix(QueenslandFLD_arr)\n",
        "# # QueenslandFLD_df_tfidf_2gram_matrix = coo_matrix(QueenslandFLD_df_tfidf_2gram)\n",
        "# # QueenslandFLD_df_tfidf_2gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_tfidf_2gram_matrix]).toarray()\n",
        "\n",
        "# # QueenslandFLD_arr_matrix = coo_matrix(QueenslandFLD_arr)\n",
        "# # QueenslandFLD_df_tfidf_3gram_matrix = coo_matrix(QueenslandFLD_df_tfidf_3gram)\n",
        "# # QueenslandFLD_df_tfidf_3gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_tfidf_3gram_matrix]).toarray()\n",
        "\n",
        "\n",
        "\n",
        "# # save to npy files\n",
        "# np.save('NepalEQ_df_tfidf_1gram_hstack.npy', NepalEQ_df_tfidf_1gram_hstack)\n",
        "# np.save('NepalEQ_df_label.npy', NepalEQ_df.label)\n",
        "# np.save('QueenslandFLD_df_tfidf_1gram_hstack.npy', QueenslandFLD_df_tfidf_1gram_hstack)\n",
        "# np.save('QueenslandFLD_df_label.npy', Queensland_FLD.label)\n",
        "\n",
        "\n"
      ],
      "id": "lY0tqcFO4O5C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fkjsd0nlQNi"
      },
      "source": [
        "#### Fasttext + hashtags + Retweets"
      ],
      "id": "0Fkjsd0nlQNi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8BJ-gAckxCd"
      },
      "outputs": [],
      "source": [
        "# # Create a sparse matrix in COO format NepalEQ_df_embeddings_fasttext\n",
        "# NepalEQ_df_embeddings_fasttext_matrix = coo_matrix(NepalEQ_df_embeddings_fasttext)\n",
        "# NepalEQ_df_embeddings_fasttext_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_embeddings_fasttext_matrix]).toarray()\n",
        "\n",
        "# # Create a sparse matrix in COO format QueenslandFLD_df_embeddings_fasttext\n",
        "# QueenslandFLD_df_embeddings_fasttext_matrix = coo_matrix(QueenslandFLD_df_embeddings_fasttext)\n",
        "# QueenslandFLD_df_embeddings_fasttext_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_embeddings_fasttext_matrix]).toarray()\n",
        "\n",
        "# np.save('NepalEQ_df_embeddings_fasttext_hstack.npy', NepalEQ_df_embeddings_fasttext_hstack)\n",
        "# np.save('QueenslandFLD_df_embeddings_fasttext_hstack.npy', QueenslandFLD_df_embeddings_fasttext_hstack)"
      ],
      "id": "Z8BJ-gAckxCd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdwqo3Ovmkl1"
      },
      "source": [
        "#### Glove + hashtags + Retweets"
      ],
      "id": "Qdwqo3Ovmkl1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5gInidnmZJC"
      },
      "outputs": [],
      "source": [
        "# # Create a sparse matrix in COO format NepalEQ_df_embeddings_glove\n",
        "# NepalEQ_df_embeddings_glove_matrix = coo_matrix(NepalEQ_df_embeddings_glove)\n",
        "# NepalEQ_df_embeddings_glove_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_embeddings_glove_matrix]).toarray()\n",
        "\n",
        "# # Create a sparse matrix in COO format QueenslandFLD_df_embeddings_glove\n",
        "# QueenslandFLD_df_embeddings_glove_matrix = coo_matrix(QueenslandFLD_df_embeddings_glove)\n",
        "# QueenslandFLD_df_embeddings_glove_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_embeddings_glove_matrix]).toarray()\n",
        "\n",
        "# np.save('NepalEQ_df_embeddings_glove_hstack.npy', NepalEQ_df_embeddings_glove_hstack)\n",
        "# np.save('QueenslandFLD_df_embeddings_glove_hstack.npy', QueenslandFLD_df_embeddings_glove_hstack)"
      ],
      "id": "Z5gInidnmZJC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSxDrDFBngcc"
      },
      "source": [
        "#### word2vec + hashtags + Retweets"
      ],
      "id": "dSxDrDFBngcc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypnBeVAnnU3J"
      },
      "outputs": [],
      "source": [
        "# # Create a sparse matrix in COO format NepalEQ_df_embeddings_word2vec\n",
        "# NepalEQ_df_embeddings_word2vec_matrix = coo_matrix(NepalEQ_df_embeddings_word2vec)\n",
        "# NepalEQ_df_embeddings_word2vec_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_embeddings_word2vec_matrix]).toarray()\n",
        "\n",
        "# # Create a sparse matrix in COO format QueenslandFLD_df_embeddings_word2vec\n",
        "# QueenslandFLD_df_embeddings_word2vec_matrix = coo_matrix(QueenslandFLD_df_embeddings_word2vec)\n",
        "# QueenslandFLD_df_embeddings_word2vec_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_embeddings_word2vec_matrix]).toarray()\n",
        "\n",
        "# np.save('NepalEQ_df_embeddings_word2vec_hstack.npy', NepalEQ_df_embeddings_word2vec_hstack)\n",
        "# np.save('QueenslandFLD_df_embeddings_word2vec_hstack.npy', QueenslandFLD_df_embeddings_word2vec_hstack)"
      ],
      "id": "ypnBeVAnnU3J"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7r0Mm08oK2f"
      },
      "source": [
        "#### bert + hashtags + Retweets"
      ],
      "id": "k7r0Mm08oK2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX9qYhSan3h8"
      },
      "outputs": [],
      "source": [
        "# # Create a sparse matrix in COO format NepalEQ_df_bert_input\n",
        "# NepalEQ_df_bert_input_matrix = coo_matrix(NepalEQ_df_bert_input)\n",
        "# NepalEQ_df_bert_input_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_bert_input_matrix]).toarray()\n",
        "\n",
        "# # Create a sparse matrix in COO format QueenslandFLD_df_bert_input\n",
        "# QueenslandFLD_df_bert_input_matrix = coo_matrix(QueenslandFLD_df_bert_input)\n",
        "# QueenslandFLD_df_bert_input_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_bert_input_matrix]).toarray()"
      ],
      "id": "qX9qYhSan3h8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOjIBrNWpPjc"
      },
      "source": [
        "#### bow + hashtags + Retweets"
      ],
      "id": "SOjIBrNWpPjc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_vOK32ZozJh"
      },
      "outputs": [],
      "source": [
        "# #NepalEQ_df_em_1gram\n",
        "# # Create a sparse matrix in COO format\n",
        "# NepalEQ_df_em_1gram_matrix = coo_matrix(NepalEQ_df_em_1gram)\n",
        "# NepalEQ_df_em_1gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_em_1gram_matrix]).toarray()\n",
        "\n",
        "# # NepalEQ_df_em_2gram_matrix = coo_matrix(NepalEQ_df_em_2gram)\n",
        "# # NepalEQ_df_em_2gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_em_2gram_matrix]).toarray()\n",
        "\n",
        "# #NepalEQ_df_em_3gram_matrix = coo_matrix(NepalEQ_df_em_3gram)\n",
        "# #NepalEQ_df_em_3gram_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_df_em_3gram_matrix]).toarray()\n",
        "\n",
        "\n",
        "# # Create a sparse matrix in COO format\n",
        "# QueenslandFLD_df_em_1gram_matrix = coo_matrix(QueenslandFLD_df_em_1gram)\n",
        "# QueenslandFLD_df_em_1gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_em_1gram_matrix]).toarray()\n",
        "\n",
        "# # QueenslandFLD_df_em_2gram_matrix = coo_matrix(QueenslandFLD_df_em_2gram)\n",
        "# # QueenslandFLD_df_em_2gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_em_2gram_matrix]).toarray()\n",
        "\n",
        "# # QueenslandFLD_df_em_3gram_matrix = coo_matrix(QueenslandFLD_df_em_3gram)\n",
        "# # QueenslandFLD_df_em_3gram_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_df_em_3gram_matrix]).toarray()\n",
        "\n",
        "# np.save('NepalEQ_df_em_1gram_hstack.npy', NepalEQ_df_em_1gram_hstack)\n",
        "# np.save('QueenslandFLD_df_em_1gram_hstack.npy', QueenslandFLD_df_em_1gram_hstack)"
      ],
      "id": "n_vOK32ZozJh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtEehs8MweBt"
      },
      "source": [
        "#### POS + hashtags + Retweets"
      ],
      "id": "DtEehs8MweBt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWKsEeXIpBp6"
      },
      "outputs": [],
      "source": [
        "# # Convert the new DataFrame to a NumPy array for NepalEQ_df\n",
        "# NepalEQ_POS_selected = NepalEQ_df[['Noun_Count_normalized', 'Verb_Count_normalized', 'Adjective_Count_normalized', 'Adverb_Count_normalized']]\n",
        "# # Convert the dataframe to a 2D array\n",
        "# NepalEQ_POS_arr = NepalEQ_POS_selected.to_numpy()\n",
        "\n",
        "# NepalEQ_POS_matrix = coo_matrix(NepalEQ_POS_arr)\n",
        "# NepalEQ_POS_hstack = hstack([NepalEQ_arr_matrix,NepalEQ_POS_matrix]).toarray()\n",
        "\n",
        "\n",
        "# # Convert the new DataFrame to a NumPy array for QueenslandFLD_df\n",
        "# QueenslandFLD_POS_selected = QueenslandFLD_df[['Noun_Count_normalized', 'Verb_Count_normalized', 'Adjective_Count_normalized', 'Adverb_Count_normalized']]\n",
        "# # Convert the dataframe to a 2D array\n",
        "# QueenslandFLD_df_POS_arr = QueenslandFLD_POS_selected.to_numpy()\n",
        "\n",
        "# QueenslandFLD_POS_matrix = coo_matrix(QueenslandFLD_df_POS_arr)\n",
        "# QueenslandFLD_POS_hstack = hstack([QueenslandFLD_arr_matrix,QueenslandFLD_POS_matrix]).toarray()\n",
        "\n",
        "\n",
        "# np.save('NepalEQ_POS_hstack.npy', NepalEQ_POS_hstack)\n",
        "# np.save('QueenslandFLD_POS_hstack.npy', QueenslandFLD_POS_hstack)"
      ],
      "id": "KWKsEeXIpBp6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFv3CyEk4B_z"
      },
      "outputs": [],
      "source": [],
      "id": "iFv3CyEk4B_z"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}