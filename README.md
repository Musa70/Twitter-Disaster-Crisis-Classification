# Twitter-Disaster-Crisis-Classification
This project focus on the use of nature language processing and deep learning techniques for disaster based Twitter classification

To conduct the experiment in this study, two publicly available real-world Twitter datasets were used. These datasets were collected during the 2013 Queensland floods and the 2015 Nepal earthquake, respectively (Alam et al., 2018). The datasets comprised millions of tweets collected through the Twitter streaming API using event-specific keywords and hashtags. The tweets were labelled as either “relevant” or “not_relevant”. Tweets that were labelled as "relevant" were those that provided crisis response information, including reports of injured or deceased individuals, damage to infrastructure, urgent needs of those affected, and requests or offers for donations. In contrast, tweets that did not contain any of the aforementioned information were labelled as "non-relevant."
The Queensland dataset used in this study was based on 10,033 randomly sampled tweets. This dataset consisted of 4,615 “relevant” tweets and 5,418 “not_relevant” tweets, with each tweet represented as a text string. The dataset was well-balanced with roughly equal numbers of tweets in each category.

Similarly, The Nepal earthquake dataset was based on a random sample of 11,668 tweets labelled as either “relevant” or “not_relevant. The number of samples in the “relevant” and “not_relevant” classes were 6,067 and 5,601, respectively. 

## References
Alam, F., Joty, S., & Imran, M. (2018). Domain Adaptation with Adversarial Training and Graph Embeddings. https://doi.org/10.48550/ARXIV.1805.05151


